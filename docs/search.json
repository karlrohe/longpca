[{"path":"/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"MIT License","title":"MIT License","text":"Copyright (c) 2024 longpca authors Permission hereby granted, free charge, person obtaining copy software associated documentation files (“Software”), deal Software without restriction, including without limitation rights use, copy, modify, merge, publish, distribute, sublicense, /sell copies Software, permit persons Software furnished , subject following conditions: copyright notice permission notice shall included copies substantial portions Software. SOFTWARE PROVIDED “”, WITHOUT WARRANTY KIND, EXPRESS IMPLIED, INCLUDING LIMITED WARRANTIES MERCHANTABILITY, FITNESS PARTICULAR PURPOSE NONINFRINGEMENT. EVENT SHALL AUTHORS COPYRIGHT HOLDERS LIABLE CLAIM, DAMAGES LIABILITY, WHETHER ACTION CONTRACT, TORT OTHERWISE, ARISING , CONNECTION SOFTWARE USE DEALINGS SOFTWARE.","code":""},{"path":"/articles/Intro_to_longpca_with_nycflights_data.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Intro_to_longpca_with_nycflights_data","text":"’ve already read readme, can skip PCA nycflights package introduces novel formula syntax PCA. modern applications (data often “long format”), formula syntax helps fluidly imagine PCA without thinking matrices. words, provides layer abstraction matrices. Given formula (long) data, code package transforms data proper format fast PCA via sparse linear algebra. package also provides code 1) help pick number dimensions compute, 2) diagnose suitability PCA (pre post PCA), 3) rotate PCs varimax, 4) visualize interpret dimensions uncovered, (yet) 5) make predictions. package uses “PCA” broad term computing leading singular vectors normalized (sometimes incomplete) matrix. might refer specific instances factor analysis, correspondence analysis, latent symantic analysis, social network analysis, low-rank matrix completion, among possible terms. big-tent PCA, included. longpca development. , functions syntax might change. current approach PCA (principal components analysis) matrix first. note begins explore alternative path, one model first. formula syntax provides alternative way think PCA makes matrices transparent; completely hidden, unless want see code. hope makes PCA legible folks yet learned linear algebra (just like linear models legible without solving linear systems equations). personally inspired approach (despite fact love matrices linear algebra) find model first way thinking much easier direct. document gives illustration data analysis popular nycflights13 data via PCA. Headline: find two seasonal effects (annual weekly) also “fly--zone” (midwest 4ever. ride die <3 much love midwest fam). Code details follow analysis. (Disclaimer: early project. , syntax code likely change great deal. Input welcome ways improve .)","code":""},{"path":"/articles/Intro_to_longpca_with_nycflights_data.html","id":"install","dir":"Articles","previous_headings":"Introduction","what":"Install","title":"Intro_to_longpca_with_nycflights_data","text":"functions PCA People contained R package longpca. already devtools installed, first need install : Thank Alex Hayes helpful feedback process suggesting name longpca.","code":"install.packages(\"devtools\") devtools::install_github(\"karlrohe/longpca\")"},{"path":"/articles/Intro_to_longpca_with_nycflights_data.html","id":"pca-the-nycflights-","dir":"Articles","previous_headings":"Introduction","what":"PCA the nycflights.","title":"Intro_to_longpca_with_nycflights_data","text":"code fast nimble: performs PCA. key innovation “formula”: ~ (month & day)*(dest), specifies model want (.e. matrix PCA). particular, perform PCA matrix rows indexed (month & day), two variables flights data. 365 unique values . columns matrix indexed destinations dest, another variable flights. 100 different destinations. multiple rows flights identical values month & day dest (e.g. lots flights LGA -> LAX every day); function pca_count fills elements matrix counting number flights day destination. similar function pca_sum allows variable left hand side formula populates elements matrix summing values. example, nycflights13 number seats available plane. can join data flights find number seats available flight. use formula seats ~(month & day)*dest inside pca_sum, perform PCA matrix elements correspond total number seats flew destination, day. output contains pc’s loadings tidy format: tidy, makes pretty easy ggplot. First, let’s rows (.e. dates). interpret pc’s, best plot contextual information /native space. dates, native space time series sequence. Let’s plot . give interpretation plots.  always think first pc “mean”. see flights less constant throughout year (see y-axis). presume oscillations weekends. pc_1 says , across destinations, flights work week fewer flights weekends. second pc gives seasonal effect (fewer flights winter, summer); importantly, pc_1, destinations negative values (.e. winter, fewer summer). third pc positive weekend destinations (flights weekends fewer weekdays relative pc_1). , like pc_2 destinations negative value (.e. flights weekends fewer weekdays relative previous two pc’s). last three harder interpret. uninformed guess artifact airline decisions. guess, ’d love hear . Also, later pick_dim, evidence noise. Now, let’s columns (.e. destinations). “native space” destinations map. Let’s plot . sure maps installed.  pc_1 align larger smaller airports (bigger airports <-> flights throughout year). pc_2 negative Denver Florida positive Maine. Looking back time series plots, interpret mean people go Denver (skiing) Florida (beach) winter Maine (coastline) summer. pc_3 picks “fly-zone”… looking back time series, folks prefer travel work week. , blue areas weekend (vacation) destinations red areas fly-. pc’s difficult interpret (guess weird artifacts airline things… noise). see last three heavily localized airports, looking back pairs plots can see localization. Given , sense interesting, needed make sense , print extreme elements dig airports. Making function todo item. , using code easy. just need specify formula. ’s fun think combinations easy try . three functions might like diagnose, pick_dim, plot explained .","code":"library(nycflights13) pcs = pca_count(~ (month & day)*(dest),                         flights,                         k = 6) dat = flights %>%    select(month, day, dest, tailnum) %>%    left_join(planes %>% select(tailnum, seats)) #> Joining with `by = join_by(tailnum)` pcs_seats = pca_sum(seats ~(month & day)*dest, dat, 6) pcs$row_features %>% sample_n(size = 3) #> # A tibble: 3 × 12 #>   month   day     n row_num degree weighted_degree pc_1_rows pc_2_rows pc_3_rows #>   <int> <int> <int>   <int>  <int>           <dbl>     <dbl>     <dbl>     <dbl> #> 1     7    24  1000      16     85            1000      1.05     1.05     0.0752 #> 2     4    14   917     251     85             917      1.00    -0.296    0.170  #> 3     3    26   973     151     86             973      1.03    -1.18    -1.04   #> # ℹ 3 more variables: pc_4_rows <dbl>, pc_5_rows <dbl>, pc_6_rows <dbl> pcs$column_features %>% sample_n(size = 3) #> # A tibble: 3 × 11 #>   dest      n col_num degree weighted_degree pc_1_columns pc_2_columns #>   <chr> <int>   <int>  <int>           <dbl>        <dbl>        <dbl> #> 1 ROC    2416      42    365            2416        0.868       -0.192 #> 2 MSN     572      70    352             572        0.409        0.639 #> 3 GRR     765      65    349             765        0.478       -0.493 #> # ℹ 4 more variables: pc_3_columns <dbl>, pc_4_columns <dbl>, #> #   pc_5_columns <dbl>, pc_6_columns <dbl> pcs = pca_count(1 ~ (month & day)*(dest), flights, k = 6)  pcs$row_features %>%    mutate(date = make_date(day = day, month=month, year = 2013)) %>%    select(date, contains(\"pc_\")) %>%    pivot_longer(contains(\"pc_\"), names_to = \"pc_dimension\", values_to = \"loadings\") %>%    ggplot(aes(x = date, y = loadings)) + geom_line() +    facet_wrap(~pc_dimension, scales= \"free\") + geom_smooth() #> `geom_smooth()` using method = 'loess' and formula = 'y ~ x' airports %>% sample_n(size = 3) #> # A tibble: 3 × 8 #>   faa   name                  lat    lon   alt    tz dst   tzone            #>   <chr> <chr>               <dbl>  <dbl> <dbl> <dbl> <chr> <chr>            #> 1 MSO   Missoula Intl        46.9 -114.   3205    -7 A     America/Denver   #> 2 CHS   Charleston Afb Intl  32.9  -80.0    45    -5 A     America/New_York #> 3 HKY   Hickory Rgnl         35.7  -81.4  1189    -5 A     America/New_York  # first, get the lat and lon for the airports: airport_dat = pcs$column_features %>%    left_join(airports %>% select(dest=faa, lat,lon)) %>%    select(lat, lon, contains(\"_col\")) %>%    pivot_longer(contains(\"pc_\"),                names_to = \"pc_dimension\", values_to = \"loadings\") %>%    drop_na() #> Joining with `by = join_by(dest)`   library(maps) usa_map <- map_data(\"state\") p <- ggplot() +    geom_polygon(data = usa_map, aes(x = long, y = lat, group = group),                 fill = \"white\", color = \"black\") +   coord_fixed(1.3, xlim = c(-125, -65), ylim = c(25, 50))  # i'm only keeping lower 48 states, dropping Anchorage and Honolulu.   p + geom_point(data = airport_dat, aes(x = lon, y = lat,                                         size = abs(loadings), color = loadings)) +   facet_wrap(~ pc_dimension)  +   scale_color_gradient2(low = \"red\", high = \"blue\", mid = \"white\")"},{"path":"/articles/Intro_to_longpca_with_nycflights_data.html","id":"a-deeper-look-inside-the-code-","dir":"Articles","previous_headings":"","what":"A deeper look inside the code.","title":"Intro_to_longpca_with_nycflights_data","text":"illustrate code, consider popular data example nycflights13 contains row every flight departing 3 main New York City airports 2013 (LGA, JFK, EWR). includes things like date, destination, information delays. many matrices “inside” data, don’t think see data. Many applications like . data look like matrix. Instead, looks like spreadsheet SQL database tibble. users think data. underneath , many possible matrices.","code":"library(nycflights13) flights #> # A tibble: 336,776 × 19 #>     year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time #>    <int> <int> <int>    <int>          <int>     <dbl>    <int>          <int> #>  1  2013     1     1      517            515         2      830            819 #>  2  2013     1     1      533            529         4      850            830 #>  3  2013     1     1      542            540         2      923            850 #>  4  2013     1     1      544            545        -1     1004           1022 #>  5  2013     1     1      554            600        -6      812            837 #>  6  2013     1     1      554            558        -4      740            728 #>  7  2013     1     1      555            600        -5      913            854 #>  8  2013     1     1      557            600        -3      709            723 #>  9  2013     1     1      557            600        -3      838            846 #> 10  2013     1     1      558            600        -2      753            745 #> # ℹ 336,766 more rows #> # ℹ 11 more variables: arr_delay <dbl>, carrier <chr>, flight <int>, #> #   tailnum <chr>, origin <chr>, dest <chr>, air_time <dbl>, distance <dbl>, #> #   hour <dbl>, minute <dbl>, time_hour <dttm>"},{"path":"/articles/Intro_to_longpca_with_nycflights_data.html","id":"a-formula-to-make-the-matrix-transparent","dir":"Articles","previous_headings":"A deeper look inside the code.","what":"A formula to make the matrix transparent","title":"Intro_to_longpca_with_nycflights_data","text":"example, flights example, make matrix every row day year every column destination airport. element matrix number flights destination day. , propose using formula, like lm. formula flights data make sparse matrix. left-hand side 1 denote just going count occurrences 336,776 rows flights. another column (e.g. size) sensible sum multiple values (e.g. number people flight, number gallons fuel consumed), size ~ (month & day)*(dest). right hand side, “interaction” parlance linear models notation lm. first terms interaction index rows matrix. , two columns flights, particular month & day. 365 unique combinations values. row. second term interaction thing, terms become columns. suggestions welcome formula syntax. Maybe also allow (month & day) ~ dest? Maybe ampersand & confusing another symbol better? thoughts? Relevant footnote: syntax also allow low-rank matrix completion, e.g. predicting arrival delay: arr_delay ~ (month & day)*(dest).","code":"formula = 1 ~ (month & day)*(dest)"},{"path":"/articles/Intro_to_longpca_with_nycflights_data.html","id":"model-first-not-matrix-first-","dir":"Articles","previous_headings":"","what":"Model first, not matrix first.","title":"Intro_to_longpca_with_nycflights_data","text":"make maximum use package, helpful think models, matrices. become clearer time goes . key functions package handling class interaction_model: im list four elements. First, $interaction_tibble can thought sparse matrix triplet form; get_Matrix(im) uses construct sparse matrix. , $row_universe $column_universe can thought holding information corresponding row/column. Finally, $settings contains various details construction. function argument parse_text uses tidytext::unnest_tokens construct “document-term interaction models”. later.","code":"im = make_interaction_model(formula, flights) im #> $row_universe #> # A tibble: 365 × 4 #>    month   day     n row_num #>    <int> <int> <int>   <int> #>  1    11    27  1014       1 #>  2     7    11  1006       2 #>  3     7     8  1004       3 #>  4     7    10  1004       4 #>  5    12     2  1004       5 #>  6     7    18  1003       6 #>  7     7    25  1003       7 #>  8     7    12  1002       8 #>  9     7     9  1001       9 #> 10     7    17  1001      10 #> # ℹ 355 more rows #>  #> $column_universe #> # A tibble: 105 × 3 #>    dest      n col_num #>    <chr> <int>   <int> #>  1 ORD   17283       1 #>  2 ATL   17215       2 #>  3 LAX   16174       3 #>  4 BOS   15508       4 #>  5 MCO   14082       5 #>  6 CLT   14064       6 #>  7 SFO   13331       7 #>  8 FLL   12055       8 #>  9 MIA   11728       9 #> 10 DCA    9705      10 #> # ℹ 95 more rows"},{"path":[]},{"path":"/articles/Intro_to_longpca_with_nycflights_data.html","id":"examining-the-matrix-sparsity","dir":"Articles","previous_headings":"Let’s do the analysis","what":"Examining the matrix sparsity","title":"Intro_to_longpca_with_nycflights_data","text":"package contains helper functions. First, lots rows columns non-zero elements, can cause “localization issues”. matrix needs “dense enough” PCA find good stuff. , diagnose prints simple diagnostics plots “degree distribution” rows columns. , “degree” number non-zero elements row column.  example, either average degree less 10, might worried. percent_le_x gives percent rows/columns row/col sums less equal x. values large, matrix sparse might trouble. Issues sparsity likely manifest localization; something evaluated functions .","code":"# inspect \"degree distributions\" with this funciton: #  recall that im is the interaction_model defined above. diagnose(im) #> # A tibble: 6 × 3 #>   measurement      dest `month & day` #>   <chr>           <dbl>         <dbl> #> 1 number_of_items   105           365 #> 2 average_degree    297            86 #> 3 median_degree     365            86 #> 4 percent_le_1        2             0 #> 5 percent_le_2        2             0 #> 6 percent_le_3        2             0"},{"path":"/articles/Intro_to_longpca_with_nycflights_data.html","id":"picking-k-with-cross-validated-eigenvalues","dir":"Articles","previous_headings":"Let’s do the analysis","what":"Picking k with cross-validated eigenvalues","title":"Intro_to_longpca_with_nycflights_data","text":"PCA, need pick number dimensions want. way lab cross-validated eigenvalues. gives Z-score p-value. arxiv paper. Alex Hayes made proper R package CRAN gdim. example, picks k=4.  Notice top-line printout says estimated graph dimension 4. , use k=6 see example become harder interpret. expect just noise… also, maybe just noise?","code":"cv_eigs = pick_dim(im, dimMax = 10,num_bootstraps = 5)  plot(cv_eigs) cv_eigs #> Estimated graph dimension:    5 #>  #> Number of bootstraps:         5 #> Edge splitting probabaility:  0.1 #> Significance level:       0.05 #>  #>  ------------ Summary of Tests ------------ #>   k          z        pvals         padj #>   1 166.971878 0.000000e+00 0.000000e+00 #>   2  11.574356 2.779341e-31 2.779341e-31 #>   3   8.104634 2.645227e-16 2.645227e-16 #>   4   4.097711 2.086283e-05 2.086283e-05 #>   5   1.801998 3.577286e-02 3.577286e-02 #>   6  -3.111896 9.990706e-01 9.990706e-01 #>   7  -5.801602 1.000000e+00 1.000000e+00 #>   8  -6.360576 1.000000e+00 1.000000e+00 #>   9  -7.387958 1.000000e+00 1.000000e+00 #>  10  -7.714933 1.000000e+00 1.000000e+00"},{"path":"/articles/Intro_to_longpca_with_nycflights_data.html","id":"lets-get-the-people-some-pca","dir":"Articles","previous_headings":"Let’s do the analysis","what":"Let’s get the people some PCA","title":"Intro_to_longpca_with_nycflights_data","text":"right now, named function pca_count, multiple rows data values (month & day) also dest, value inside matrix sum values left hand side formula. Right now, just 1. , counts many times entry appears. people call cross-tab contingency table. PCA matrix counts, folks call Correspondence Analysis. particular, code takes square root every count. , computes normalized regularized Laplacian L (using number non-zero entries degree). , computes leading k singular vectors. done sparse linear algebra via packages Matrix irlba. row_features column_features PC’s loadings (don’t prefer old terms). middle_B gives singular values. settings contains details handy later functions. Notice features wide tidy form, making easy lubridate::make_date (row_features) left-join airports (get latitude longitude) column_features.","code":"pcs = pca_count(formula, tib = flights, k = 6)  # There are two other ways to accomplish the same thing: pcs_with_sum = pca_sum(formula, tib = flights, k = 6) # or directly with the interaction_model object via the function pca: pcs_with_im = pca(im, k = 6) names(pcs) #> [1] \"row_features\"    \"column_features\" \"middle_B\"        \"settings\" sample_n(pcs$row_features, size = 3) #> # A tibble: 3 × 12 #>   month   day     n row_num degree weighted_degree pc_1_rows pc_2_rows pc_3_rows #>   <int> <int> <int>   <int>  <int>           <dbl>     <dbl>     <dbl>     <dbl> #> 1     9     3   956     203     86             956     1.02      -1.06   -0.483  #> 2     7    15   999      21     85             999     1.04      -1.05    0.0634 #> 3     3    17   907     269     88             907     0.985      1.42   -0.284  #> # ℹ 3 more variables: pc_4_rows <dbl>, pc_5_rows <dbl>, pc_6_rows <dbl> sample_n(pcs$column_features, size=3) #> # A tibble: 3 × 11 #>   dest      n col_num degree weighted_degree pc_1_columns pc_2_columns #>   <chr> <int>   <int>  <int>           <dbl>        <dbl>        <dbl> #> 1 LGA       1     105      1               1      0.00127     -0.00987 #> 2 BZN      36      96     36              36      0.0437       0.412   #> 3 ALB     439      74    260             439      0.336        1.72    #> # ℹ 4 more variables: pc_3_columns <dbl>, pc_4_columns <dbl>, #> #   pc_5_columns <dbl>, pc_6_columns <dbl>"},{"path":"/articles/Intro_to_longpca_with_nycflights_data.html","id":"diagnostic-plots","dir":"Articles","previous_headings":"","what":"Intro_to_longpca_with_nycflights_data","title":"Intro_to_longpca_with_nycflights_data","text":"can plot(pcs). makes five plots, described plots displayed.      five plots: Screeplot: top k singular values L. Better screeplot: singular values 2:k (first one usually dominant difficult see elbow past ). “localization plot” similar (maybe exact?) stuff; row (column) compute degree leverage score. Take log . Fit linear model log(leverage)~log(degree) plot residuals log(degree). localization, suspect big curl right side. Pairs plot row_features. plot emphasized varimax paper. example plots , see clear radial streaks. pairs plot column_features. pairs plots, 1000 points, code samples 1000 points probability proportional leverage scores. plot k=10 dimensions. k larger, plots first 5 last 5.","code":"plot(pcs) #> Press [Enter] to continue to the next plot... #> Press [Enter] to continue to the next plot... #> `geom_smooth()` using formula = 'y ~ s(x, bs = \"cs\")' #> Press [Enter] to continue to the next plot... #> Press [Enter] to continue to the next plot..."},{"path":"/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Rohe Karl. Author, maintainer.","code":""},{"path":"/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Karl R (2024). longpca: formula interface model-first PCA; PCA people!. R package version 0.0.0.9000, https://github.com/karlrohe/longpca.","code":"@Manual{,   title = {longpca: A formula interface for model-first PCA; PCA for the people!},   author = {Rohe Karl},   year = {2024},   note = {R package version 0.0.0.9000},   url = {https://github.com/karlrohe/longpca}, }"},{"path":"/index.html","id":"pca-for-the-people","dir":"","previous_headings":"","what":"A formula interface for model-first PCA; PCA for the people!","title":"A formula interface for model-first PCA; PCA for the people!","text":"Karl Rohe 2024-01-03 package introduces novel formula syntax PCA. modern applications (data often “long format”), formula syntax helps fluidly imagine PCA without thinking matrices. words, provides layer abstraction matrices. Given formula (long) data, code package transforms data proper format fast PCA via sparse linear algebra. package also provides code 1) help pick number dimensions compute, 2) diagnose suitability PCA (pre post PCA), 3) rotate PCs varimax, 4) visualize interpret dimensions uncovered, (yet) 5) make predictions. package uses “PCA” broad term computing leading singular vectors normalized (sometimes incomplete) matrix. might refer specific instances factor analysis, correspondence analysis, latent symantic analysis, social network analysis, low-rank matrix completion, among possible terms. big-tent PCA, included. longpca development. , functions syntax might change. current approach PCA (principal components analysis) matrix first. note begins explore alternative path, one model first. formula syntax provides alternative way think PCA makes matrices transparent; completely hidden, unless want see code. hope makes PCA legible folks yet learned linear algebra (just like linear models legible without solving linear systems equations). personally inspired approach (despite fact love matrices linear algebra) find model first way thinking much easier direct. document gives illustration data analysis popular nycflights13 data via PCA. Headline: find two seasonal effects (annual weekly) also “fly--zone” (midwest 4ever. ride die <3 much love midwest fam). Code details follow analysis. (Disclaimer: early project. , syntax code likely change great deal. Input welcome ways improve .)","code":""},{"path":"/index.html","id":"install","dir":"","previous_headings":"","what":"Install","title":"A formula interface for model-first PCA; PCA for the people!","text":"functions PCA People contained R package longpca. already devtools installed, first need install : Thank Alex Hayes helpful feedback process suggesting name longpca.","code":"install.packages(\"devtools\") devtools::install_github(\"karlrohe/longpca\")"},{"path":"/index.html","id":"pca-the-nycflights","dir":"","previous_headings":"","what":"PCA the nycflights.","title":"A formula interface for model-first PCA; PCA for the people!","text":"code fast nimble. First define “model” formula… data: three functions run im: diagnose, pick_dim, pca. three key functions run pcs: plot, rotate, top. See vignettes illustrations: depth example nycflights13 data Inside make_interaction_model, can parse_text","code":"formula = 1 ~ (month & day)*(dest) im = make_interaction_model(formula, flights) pcs = pca(im, k = 6)"},{"path":"/index.html","id":"slightly-more-detail","dir":"","previous_headings":"PCA the nycflights.","what":"Slightly more detail…","title":"A formula interface for model-first PCA; PCA for the people!","text":"hope model first PCA formula makes interacting matrix / linear algebra unnecessary. said, might instructive understand class interaction_model see represents matrix “hood”. function make_interaction_model constructs list class interaction_model. can think abstraction matrix… “matrix like thing,” month & day index rows dest indexes columns. month & day come interaction * formula dest comes afterwords. , “matrix” sparse triplet form: reason actually wanted sparse Matrix… hope model first PCA interaction_model makes data analysis direct, .e. need think matrix (much). Instead, path simply way estimate “low rank” statistical model via least squares.","code":"formula = 1 ~ (month & day)*(dest) im = make_interaction_model(formula, flights) names(im) ## [1] \"interaction_tibble\" \"row_universe\"       \"column_universe\"    ## [4] \"settings\" class(im) ## [1] \"interaction_model\" im$row_universe ## # A tibble: 365 × 4 ##    month   day     n row_num ##    <int> <int> <int>   <int> ##  1    11    27  1014       1 ##  2     7    11  1006       2 ##  3     7     8  1004       3 ##  4     7    10  1004       4 ##  5    12     2  1004       5 ##  6     7    18  1003       6 ##  7     7    25  1003       7 ##  8     7    12  1002       8 ##  9     7     9  1001       9 ## 10     7    17  1001      10 ## # ℹ 355 more rows im$column_universe ## # A tibble: 105 × 3 ##    dest      n col_num ##    <chr> <int>   <int> ##  1 ORD   17283       1 ##  2 ATL   17215       2 ##  3 LAX   16174       3 ##  4 BOS   15508       4 ##  5 MCO   14082       5 ##  6 CLT   14064       6 ##  7 SFO   13331       7 ##  8 FLL   12055       8 ##  9 MIA   11728       9 ## 10 DCA    9705      10 ## # ℹ 95 more rows im$interaction_tibble ## # A tibble: 31,229 × 3 ##    row_num col_num outcome ##      <int>   <int>   <dbl> ##  1       1       1      52 ##  2       1       2      51 ##  3       1       3      49 ##  4       1       4      43 ##  5       1       5      40 ##  6       1       6      42 ##  7       1       7      43 ##  8       1       8      38 ##  9       1       9      37 ## 10       1      10      28 ## # ℹ 31,219 more rows A = get_Matrix(im, import_names = TRUE) str(A) ## Formal class 'dgCMatrix' [package \"Matrix\"] with 6 slots ##   ..@ i       : int [1:31229] 0 1 2 3 4 5 6 7 8 9 ... ##   ..@ p       : int [1:106] 0 365 730 1095 1460 1825 2190 2555 2920 3285 ... ##   ..@ Dim     : int [1:2] 365 105 ##   ..@ Dimnames:List of 2 ##   .. ..$ : chr [1:365] \"11/27\" \"7/11\" \"7/8\" \"7/10\" ... ##   .. ..$ : chr [1:105] \"ORD\" \"ATL\" \"LAX\" \"BOS\" ... ##   ..@ x       : num [1:31229] 52 55 55 55 49 54 55 55 54 55 ... ##   ..@ factors : list()"},{"path":"/reference/diagnose.html","id":null,"dir":"Reference","previous_headings":"","what":"diagnose_formula — diagnose","title":"diagnose_formula — diagnose","text":"function helps see \"enough data\" pca return reliable results. particular, examine degree distribution printout plot. Perhaps run function running pca.","code":""},{"path":"/reference/diagnose.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"diagnose_formula — diagnose","text":"","code":"diagnose(im, make_plot = TRUE, nbins = 30)"},{"path":"/reference/diagnose.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"diagnose_formula — diagnose","text":"make_plot","code":""},{"path":"/reference/diagnose.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"diagnose_formula — diagnose","text":"","code":"library(nycflights13) im = make_interaction_model(~(month&day)*dest, flights) diagnose(im) #> Warning: log-10 transformation introduced infinite values. #> Warning: Removed 28 rows containing missing values or values outside the scale range #> (`geom_bar()`).  #> # A tibble: 6 × 3 #>   measurement      dest `month & day` #>   <chr>           <dbl>         <dbl> #> 1 number_of_items   105           365 #> 2 average_degree    297            86 #> 3 median_degree     365            86 #> 4 percent_le_1        2             0 #> 5 percent_le_2        2             0 #> 6 percent_le_3        2             0"},{"path":"/reference/extract_interaction.html","id":null,"dir":"Reference","previous_headings":"","what":"extract_interaction (internal) — extract_interaction","title":"extract_interaction (internal) — extract_interaction","text":"extract_interaction (internal)","code":""},{"path":"/reference/extract_interaction.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"extract_interaction (internal) — extract_interaction","text":"","code":"extract_interaction(str)"},{"path":"/reference/extract_interaction.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"extract_interaction (internal) — extract_interaction","text":"str","code":""},{"path":"/reference/extract_interaction.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"extract_interaction (internal) — extract_interaction","text":"vector terms inside interaction","code":""},{"path":"/reference/extract_variables.html","id":null,"dir":"Reference","previous_headings":"","what":"extract_variables (internal) — extract_variables","title":"extract_variables (internal) — extract_variables","text":"extract_variables (internal)","code":""},{"path":"/reference/extract_variables.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"extract_variables (internal) — extract_variables","text":"","code":"extract_variables(str)"},{"path":"/reference/extract_variables.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"extract_variables (internal) — extract_variables","text":"str","code":""},{"path":"/reference/get_Matrix.html","id":null,"dir":"Reference","previous_headings":"","what":"get_Matrix — get_Matrix","title":"get_Matrix — get_Matrix","text":"get_Matrix","code":""},{"path":"/reference/get_Matrix.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"get_Matrix — get_Matrix","text":"","code":"get_Matrix(interaction_model, import_names = FALSE)"},{"path":"/reference/get_Matrix.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"get_Matrix — get_Matrix","text":"interaction_model","code":""},{"path":"/reference/glaplacian.html","id":null,"dir":"Reference","previous_headings":"","what":"glaplacian — glaplacian","title":"glaplacian — glaplacian","text":"Normalizes regularizes sparse adjacency Matrix deg_row deg_col number non-zero elements row/column","code":""},{"path":"/reference/glaplacian.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"glaplacian — glaplacian","text":"","code":"glaplacian(A, regularize = TRUE)"},{"path":"/reference/glaplacian.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"glaplacian — glaplacian","text":"regularize","code":""},{"path":"/reference/itty_pivot.html","id":null,"dir":"Reference","previous_headings":"","what":"itty_pivot (internal) — itty_pivot","title":"itty_pivot (internal) — itty_pivot","text":"used diagnose","code":""},{"path":"/reference/itty_pivot.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"itty_pivot (internal) — itty_pivot","text":"","code":"itty_pivot(itty_tibby)"},{"path":"/reference/itty_pivot.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"itty_pivot (internal) — itty_pivot","text":"itty_tibby","code":""},{"path":"/reference/localization.html","id":null,"dir":"Reference","previous_headings":"","what":"localization — localization","title":"localization — localization","text":"Plots degree vs leverage; specifically, residual log(leverage)~log(degree) log(degree).","code":""},{"path":"/reference/localization.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"localization — localization","text":"","code":"localization(pcs)"},{"path":"/reference/localization.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"localization — localization","text":"pcs","code":""},{"path":"/reference/make_deg_lev_resid.html","id":null,"dir":"Reference","previous_headings":"","what":"make_deg_lev_resid (Internal) — make_deg_lev_resid","title":"make_deg_lev_resid (Internal) — make_deg_lev_resid","text":"make_deg_lev_resid (Internal)","code":""},{"path":"/reference/make_deg_lev_resid.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"make_deg_lev_resid (Internal) — make_deg_lev_resid","text":"","code":"make_deg_lev_resid(lev_tib)"},{"path":"/reference/make_deg_lev_resid.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"make_deg_lev_resid (Internal) — make_deg_lev_resid","text":"lev_tib","code":""},{"path":"/reference/make_interaction_model.html","id":null,"dir":"Reference","previous_headings":"","what":"make_interaction_model — make_interaction_model","title":"make_interaction_model — make_interaction_model","text":"generates interaction_model object.  comfortable thinking matrices, can think matrix-like-object.","code":""},{"path":"/reference/make_interaction_model.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"make_interaction_model — make_interaction_model","text":"","code":"make_interaction_model(   fo,   tib,   duplicates = \"add\",   parse_text = FALSE,   dropNA = TRUE,   data_prefix = NULL,   ... )"},{"path":"/reference/make_interaction_model.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"make_interaction_model — make_interaction_model","text":"fo formula, like outcome ~ (row_nums & context) * measurement_type. tib tibble contains variables formula. exception left-hand-side can 1 need tib. parse_text set TRUE, right side * (.e. measurement_type) parsed sequence tokens via tidytext::unnest_tokens.  Additional arguments ... passed unnest_tokens.  example, adding to_lower = FALSE ensure case kept. Additionally, set token something words (ngrams skip_ngrams additionally specify n = ).  See unnest_token arguments. dropNA recommended.  drops rows tib NA's among essential variables.","code":""},{"path":"/reference/make_interaction_model.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"make_interaction_model — make_interaction_model","text":"list four elements.  First, interaction_tibble, akin sparse matrix triplet form. Second, row_universe akin row names , tidy form.  Thir, column_universe like row_universe. Fourth, settings.","code":""},{"path":"/reference/make_interaction_model.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"make_interaction_model — make_interaction_model","text":"","code":"library(nycflights13) im = make_interaction_model(~(month & day)*dest, flights) names(im) #> [1] \"interaction_tibble\" \"row_universe\"       \"column_universe\"    #> [4] \"settings\"           im$row_universe #> # A tibble: 365 × 4 #>    month   day     n row_num #>    <int> <int> <int>   <int> #>  1    11    27  1014       1 #>  2     7    11  1006       2 #>  3     7     8  1004       3 #>  4     7    10  1004       4 #>  5    12     2  1004       5 #>  6     7    18  1003       6 #>  7     7    25  1003       7 #>  8     7    12  1002       8 #>  9     7     9  1001       9 #> 10     7    17  1001      10 #> # ℹ 355 more rows im$column_universe #> # A tibble: 105 × 3 #>    dest      n col_num #>    <chr> <int>   <int> #>  1 ORD   17283       1 #>  2 ATL   17215       2 #>  3 LAX   16174       3 #>  4 BOS   15508       4 #>  5 MCO   14082       5 #>  6 CLT   14064       6 #>  7 SFO   13331       7 #>  8 FLL   12055       8 #>  9 MIA   11728       9 #> 10 DCA    9705      10 #> # ℹ 95 more rows im$interaction_tibble #> # A tibble: 31,229 × 3 #>    row_num col_num outcome #>      <int>   <int>   <dbl> #>  1       1       1      52 #>  2       1       2      51 #>  3       1       3      49 #>  4       1       4      43 #>  5       1       5      40 #>  6       1       6      42 #>  7       1       7      43 #>  8       1       8      38 #>  9       1       9      37 #> 10       1      10      28 #> # ℹ 31,219 more rows im$settings #> $fo #> 1 ~ (month & day) * dest #> <environment: 0x7faba7d2b808> #>  #> $data_prefix #> NULL #>  #> $outcome_aggregation #> [1] \"count\" #>  #> $outcome_variables #> [1] \"outcome_unweighted_1\" #>  #> $row_variables #> [1] \"month\" \"day\"   #>  #> $column_variables #> [1] \"dest\" #>  # you can extract the sparse Matrix: A = longpca:::get_Matrix(im,  import_names = TRUE) str(A) #> Formal class 'dgCMatrix' [package \"Matrix\"] with 6 slots #>   ..@ i       : int [1:31229] 0 1 2 3 4 5 6 7 8 9 ... #>   ..@ p       : int [1:106] 0 365 730 1095 1460 1825 2190 2555 2920 3285 ... #>   ..@ Dim     : int [1:2] 365 105 #>   ..@ Dimnames:List of 2 #>   .. ..$ : chr [1:365] \"11/27\" \"7/11\" \"7/8\" \"7/10\" ... #>   .. ..$ : chr [1:105] \"ORD\" \"ATL\" \"LAX\" \"BOS\" ... #>   ..@ x       : num [1:31229] 52 55 55 55 49 54 55 55 54 55 ... #>   ..@ factors : list() im = make_interaction_model(~Package*Imports, all_packages, parse_text = TRUE) names(im) #> [1] \"interaction_tibble\" \"row_universe\"       \"column_universe\"    #> [4] \"settings\"           im$row_universe #> # A tibble: 20,319 × 3 #>    Package                n row_num #>    <chr>              <int>   <int> #>  1 Seurat                64       1 #>  2 tidyverse             60       2 #>  3 radiant.data          58       3 #>  4 radiant.model         58       4 #>  5 SSDM                  55       5 #>  6 BasketballAnalyzeR    53       6 #>  7 tRigon                49       7 #>  8 AFM                   48       8 #>  9 dextergui             48       9 #> 10 proteus               48      10 #> # ℹ 20,309 more rows im$column_universe #> # A tibble: 6,230 × 4 #>    from_text token        n col_num #>    <chr>     <chr>    <int>   <int> #>  1 Imports   stats     5442       1 #>  2 Imports   utils     3423       2 #>  3 Imports   dplyr     3299       3 #>  4 Imports   methods   3210       4 #>  5 Imports   ggplot2   3135       5 #>  6 Imports   rcpp      2548       6 #>  7 Imports   rlang     2172       7 #>  8 Imports   graphics  2158       8 #>  9 Imports   magrittr  1954       9 #> 10 Imports   stringr   1698      10 #> # ℹ 6,220 more rows im$interaction_tibble #> # A tibble: 114,833 × 3 #>    row_num col_num outcome #>      <int>   <int>   <dbl> #>  1       1       1       1 #>  2       1       2       1 #>  3       1       5       1 #>  4       1       6       1 #>  5       1       7       1 #>  6       1       8       1 #>  7       1      12       1 #>  8       1      13       1 #>  9       1      14       1 #> 10       1      15       1 #> # ℹ 114,823 more rows im$settings #> $fo #> 1 ~ Package * Imports #> <environment: 0x7faba11dab98> #>  #> $data_prefix #> [1] \"text\" #>  #> $outcome_aggregation #> [1] \"count\" #>  #> $outcome_variables #> [1] \"outcome_unweighted_1\" #>  #> $row_variables #> [1] \"Package\" #>  #> $column_variables #> [1] \"from_text\" \"token\"     #>"},{"path":"/reference/make_interaction_model_from_variables.html","id":null,"dir":"Reference","previous_headings":"","what":"make_interaction_model_from_variables (internal to make_interaction_tibble and text2sparse) — make_interaction_model_from_variables","title":"make_interaction_model_from_variables (internal to make_interaction_tibble and text2sparse) — make_interaction_model_from_variables","text":"make_interaction_model_from_variables (internal make_interaction_tibble text2sparse)","code":""},{"path":"/reference/make_interaction_model_from_variables.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"make_interaction_model_from_variables (internal to make_interaction_tibble and text2sparse) — make_interaction_model_from_variables","text":"","code":"make_interaction_model_from_variables(   tib,   row_column,   column_column,   outcome_column,   vars = NULL,   dropNA,   duplicates )"},{"path":"/reference/make_interaction_model_from_variables.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"make_interaction_model_from_variables (internal to make_interaction_tibble and text2sparse) — make_interaction_model_from_variables","text":"outcome_column","code":""},{"path":"/reference/make_leverage.html","id":null,"dir":"Reference","previous_headings":"","what":"make_leverage (internal for localization) — make_leverage","title":"make_leverage (internal for localization) — make_leverage","text":"make_leverage (internal localization)","code":""},{"path":"/reference/make_leverage.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"make_leverage (internal for localization) — make_leverage","text":"","code":"make_leverage(pcs)"},{"path":"/reference/make_leverage.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"make_leverage (internal for localization) — make_leverage","text":"pcs","code":""},{"path":"/reference/make_sparse_output.html","id":null,"dir":"Reference","previous_headings":"","what":"make_sparse_output (internal to rotate) — make_sparse_output","title":"make_sparse_output (internal to rotate) — make_sparse_output","text":"make_sparse_output (internal rotate)","code":""},{"path":"/reference/make_sparse_output.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"make_sparse_output (internal to rotate) — make_sparse_output","text":"","code":"make_sparse_output(sparse_pc_mat, rot_mat, new_prefix)"},{"path":"/reference/make_sparse_output.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"make_sparse_output (internal to rotate) — make_sparse_output","text":"old_prefix","code":""},{"path":"/reference/pair.html","id":null,"dir":"Reference","previous_headings":"","what":"Internal — pair","title":"Internal — pair","text":"Internal","code":""},{"path":"/reference/pair.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Internal — pair","text":"","code":"pair(u, n = 1000)"},{"path":"/reference/pair.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Internal — pair","text":"n","code":""},{"path":"/reference/parse_formula.html","id":null,"dir":"Reference","previous_headings":"","what":"parse_variables (internal) — parse_formula","title":"parse_variables (internal) — parse_formula","text":"parse_variables (internal)","code":""},{"path":"/reference/parse_formula.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"parse_variables (internal) — parse_formula","text":"","code":"parse_formula(fo, tib)"},{"path":"/reference/parse_formula.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"parse_variables (internal) — parse_formula","text":"tib","code":""},{"path":"/reference/pca.html","id":null,"dir":"Reference","previous_headings":"","what":"pca — pca","title":"pca — pca","text":"pca","code":""},{"path":"/reference/pca.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"pca — pca","text":"","code":"pca(im, k, method_prefix = \"pc\", regularize = TRUE, sqrt_counts = TRUE)"},{"path":"/reference/pca.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"pca — pca","text":"method_prefix","code":""},{"path":"/reference/pca_average.html","id":null,"dir":"Reference","previous_headings":"","what":"pca_average — pca_average","title":"pca_average — pca_average","text":"performs pca matrix missing entries.","code":""},{"path":"/reference/pca_average.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"pca_average — pca_average","text":"","code":"pca_average(fo, tib, k)"},{"path":"/reference/pca_average.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"pca_average — pca_average","text":"k","code":""},{"path":"/reference/pca_count.html","id":null,"dir":"Reference","previous_headings":"","what":"pca_count — pca_count","title":"pca_count — pca_count","text":"first user function generate pcs.","code":""},{"path":"/reference/pca_count.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"pca_count — pca_count","text":"","code":"pca_count(fo, tib, k)"},{"path":"/reference/pca_count.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"pca_count — pca_count","text":"fo formula, like  ~ (row_ids & context) * measurement_type. left hand side left empty.  , converted 1. Either way, elements sparse matrix just counts. tib tibble contains variables formula. exception left-hand-side can 1 need tib. k number dimensions pca","code":""},{"path":"/reference/pca_count.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"pca_count — pca_count","text":"output list : (1) row_features whichever term first right hand side formula, (2) column_features whichever term second right hand side formula, (3) middle_B tibble corresponding diagonal matrix sparse triplet form, (4) settings list details.","code":""},{"path":"/reference/pca_sum.html","id":null,"dir":"Reference","previous_headings":"","what":"pca_sum — pca_sum","title":"pca_sum — pca_sum","text":"performs pca sparse Matrix specified formula tibble.","code":""},{"path":"/reference/pca_sum.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"pca_sum — pca_sum","text":"","code":"pca_sum(fo, tib, k)"},{"path":"/reference/pca_sum.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"pca_sum — pca_sum","text":"fo formula, like  outcome ~ (row_ids & context) * measurement_type. tib tibble contains variables formula. exception left-hand-side can 1 need tib. k number dimensions pca","code":""},{"path":"/reference/pca_sum.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"pca_sum — pca_sum","text":"output list : (1) row_features whichever term first right hand side formula, (2) column_features whichever term second right hand side formula, (3) middle_B tibble corresponding diagonal matrix sparse triplet form, (4) settings list details.","code":""},{"path":"/reference/pca_text.html","id":null,"dir":"Reference","previous_headings":"","what":"pca_text — pca_text","title":"pca_text — pca_text","text":"given formula ~ row_ids * text, text character string, construct matrix row's indexed row_ids columns (default) bag--words. Perform PCA matrix.","code":""},{"path":"/reference/pca_text.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"pca_text — pca_text","text":"","code":"pca_text(fo, tib, k, ...)"},{"path":"/reference/pca_text.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"pca_text — pca_text","text":"...","code":""},{"path":"/reference/pca_text.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"pca_text — pca_text","text":"Extended arguments ... passed tidytext::unnest_tokens. example ... token = \"ngrams\", n=2 construct matrix bigrams. TODO: make diagnose_text","code":""},{"path":"/reference/pick_dim.html","id":null,"dir":"Reference","previous_headings":"","what":"pick_dim — pick_dim","title":"pick_dim — pick_dim","text":"computes Z-scores cross-validated eigenvalues","code":""},{"path":"/reference/pick_dim.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"pick_dim — pick_dim","text":"","code":"pick_dim(im, dimMax = 20, num_bootstraps = 2)"},{"path":"/reference/pick_dim.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"pick_dim — pick_dim","text":"num_bootstraps","code":""},{"path":"/reference/pick_dim.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"pick_dim — pick_dim","text":"","code":"library(nycflights13) im = make_interaction_model(~(month&day)*dest, flights) cveig = pick_dim(im, dimMax = 7) plot(cveig)  cveig #> Estimated graph dimension:\t 4 #>  #> Number of bootstraps:\t\t 2 #> Edge splitting probabaility:\t 0.1 #> Significance level:\t\t 0.05 #>  #>  ------------ Summary of Tests ------------ #>  k           z        pvals         padj #>  1 166.5845382 0.000000e+00 0.000000e+00 #>  2  12.5981739 1.080448e-36 1.080448e-36 #>  3   8.2016440 1.185608e-16 1.185608e-16 #>  4   4.3154305 7.964608e-06 7.964608e-06 #>  5   0.5997185 2.743469e-01 2.743469e-01 #>  6  -1.9878241 9.765844e-01 9.765844e-01 #>  7  -3.9122195 9.999543e-01 9.999543e-01 #>"},{"path":"/reference/plot.pc.html","id":null,"dir":"Reference","previous_headings":"","what":"plot.pc — plot.pc","title":"plot.pc — plot.pc","text":"creates five diagnostic plots: Screeplot: top k singular values L. Better screeplot: singular values 2:k (first one usually dominant difficult see elbow past ). \"localization plot\" similar (maybe exact?) stuff; row (column) compute degree leverage score.  Take log . Fit linear model log(leverage)~log(degree) plot residuals log(degree).  localization, suspect big curl right side. Pairs plot row_features. plot emphasized varimax paper. example plots , see clear radial streaks. pairs plot column_features.  pairs plots, 1000 points, code samples 1000 points probability proportional leverage scores.  plot k=10 dimensions.  k larger, plots first 5 last 5.","code":""},{"path":"/reference/plot.pc.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"plot.pc — plot.pc","text":"","code":"# S3 method for pc plot(pcs)"},{"path":"/reference/plot.pc.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"plot.pc — plot.pc","text":"pcs","code":""},{"path":"/reference/plot.pc.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"plot.pc — plot.pc","text":"","code":"library(nycflights13) pcs = pca_count(1 ~ (month & day)*(dest), flights, k = 6) plot(pcs)  #> Press [Enter] to continue to the next plot...  #> Press [Enter] to continue to the next plot... #> `geom_smooth()` using formula = 'y ~ s(x, bs = \"cs\")'  #> Press [Enter] to continue to the next plot...  #> Press [Enter] to continue to the next plot..."},{"path":"/reference/print.interaction_model.html","id":null,"dir":"Reference","previous_headings":"","what":"print interaction model — print.interaction_model","title":"print interaction model — print.interaction_model","text":"print interaction model","code":""},{"path":"/reference/print.interaction_model.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"print interaction model — print.interaction_model","text":"","code":"# S3 method for interaction_model print(im)"},{"path":"/reference/print.interaction_model.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"print interaction model — print.interaction_model","text":"im","code":""},{"path":"/reference/print.pc.html","id":null,"dir":"Reference","previous_headings":"","what":"print.pc — print.pc","title":"print.pc — print.pc","text":"print.pc","code":""},{"path":"/reference/print.pc.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"print.pc — print.pc","text":"","code":"# S3 method for pc print(pcs)"},{"path":"/reference/print.pc.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"print.pc — print.pc","text":"pcs","code":""},{"path":"/reference/remove_L_normalization.html","id":null,"dir":"Reference","previous_headings":"","what":"remove_L_normalization (internal to pca_mean/pca_average) — remove_L_normalization","title":"remove_L_normalization (internal to pca_mean/pca_average) — remove_L_normalization","text":"remove_L_normalization (internal pca_mean/pca_average)","code":""},{"path":"/reference/remove_L_normalization.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"remove_L_normalization (internal to pca_mean/pca_average) — remove_L_normalization","text":"","code":"remove_L_normalization(s_svd, A, orthogonalize = FALSE)"},{"path":"/reference/remove_L_normalization.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"remove_L_normalization (internal to pca_mean/pca_average) — remove_L_normalization","text":"orthogonalize","code":""},{"path":"/reference/rotate.html","id":null,"dir":"Reference","previous_headings":"","what":"rotate — rotate","title":"rotate — rotate","text":"perform varimax rotation rows columns.  mode specified, mode rotated.","code":""},{"path":"/reference/rotate.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"rotate — rotate","text":"","code":"rotate(pcs, mode = NULL)"},{"path":"/reference/rotate.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"rotate — rotate","text":"mode specify row column want rotate one mode.","code":""},{"path":"/reference/rotate.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"rotate — rotate","text":"","code":"im = make_interaction_model(~Package*Imports, all_packages, parse_text = TRUE) pcs = pca(im, k = 10) # streaks(pcs) sparse_pcs = rotate(pcs) # notice how the rotation aligns the streaks with the axes... # streaks(sparse_pcs, \"columns\") # if you do not specify a mode, then the middle B matrix will not be strictly diagonal... image(longpca:::get_middle_matrix(sparse_pcs))  # if you rotate only the columns, then the middle B matrix is set to diagonal and this matrix is \"pushed into\" the other mode. sparse_columns_pcs = rotate(pcs, mode = \"columns\") # because we only rotated one mode, the B matrix is the identity matrix: image(longpca:::get_middle_matrix(sparse_columns_pcs))  # these values were pushed into the row_features.  You can see that their scale is drastically reduced: sparse_pcs$row_features$vpc_01_rows |> sd() #> [1] 0.9769103 sparse_columns_pcs$row_features$vpc_01_rows |> sd() #> [1] 5.553318e-05 # importantly, this is not simply the row pcs scaled by the singular values... it is also rotated by the varimax rotation for the columns... # here is the algebra using the SVD: # U D V' = (UDR)(VR)' # after rotating only the columns... # (UDR) gives the new row_features # (VR) gives the new column_features"},{"path":"/reference/select_universe.html","id":null,"dir":"Reference","previous_headings":"","what":"select_universe — select_universe","title":"select_universe — select_universe","text":"select_universe","code":""},{"path":"/reference/select_universe.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"select_universe — select_universe","text":"","code":"select_universe(pcs, mode = c(\"rows\", \"columns\"), any_dims = NA)"},{"path":"/reference/select_universe.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"select_universe — select_universe","text":"any_dims","code":""},{"path":"/reference/streaks.html","id":null,"dir":"Reference","previous_headings":"","what":"streaks — streaks","title":"streaks — streaks","text":"pairs plot.  Set type_mode either \"rows\" \"cols\".  plot_columns pick columns.","code":""},{"path":"/reference/streaks.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"streaks — streaks","text":"","code":"streaks(pcs, mode = \"rows\", plot_columns = NULL)"},{"path":"/reference/streaks.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"streaks — streaks","text":"plot_columns","code":""},{"path":"/reference/summary.interaction_model.html","id":null,"dir":"Reference","previous_headings":"","what":"summary interaction model — summary.interaction_model","title":"summary interaction model — summary.interaction_model","text":"summary interaction model","code":""},{"path":"/reference/summary.interaction_model.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"summary interaction model — summary.interaction_model","text":"","code":"# S3 method for interaction_model summary(im)"},{"path":"/reference/summary.interaction_model.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"summary interaction model — summary.interaction_model","text":"im","code":""},{"path":"/reference/top.html","id":null,"dir":"Reference","previous_headings":"","what":"Title — top","title":"Title — top","text":"Title","code":""},{"path":"/reference/top.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Title — top","text":"","code":"top(pcs, this_dim, keep_how_many = 9, abs_cut_off = 3)"},{"path":"/reference/top.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Title — top","text":"dim","code":""},{"path":"/reference/top_features.html","id":null,"dir":"Reference","previous_headings":"","what":"top_features — top_features","title":"top_features — top_features","text":"top_features","code":""},{"path":"/reference/top_features.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"top_features — top_features","text":"","code":"top_features(tidy_features, pc_name_for_mode, keep_how_many)"},{"path":"/reference/top_features.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"top_features — top_features","text":"dim_string","code":""},{"path":"/reference/transpose_tibble.html","id":null,"dir":"Reference","previous_headings":"","what":"#' list_2_tib (internal)\n#'\n#' used for diagnose\n#'\n#' @param list_of_data\n#'\n#' @return\n#'\n#' @examples\nlist_2_tib = function(list_of_data)\ndplyr::bind_rows(lapply(list_of_data, itty_pivot)) — transpose_tibble","title":"#' list_2_tib (internal)\n#'\n#' used for diagnose\n#'\n#' @param list_of_data\n#'\n#' @return\n#'\n#' @examples\nlist_2_tib = function(list_of_data)\ndplyr::bind_rows(lapply(list_of_data, itty_pivot)) — transpose_tibble","text":"#' list_2_tib (internal) #' #' used diagnose #' #' @param list_of_data #' #' @return #' #' @examples list_2_tib = function(list_of_data) dplyr::bind_rows(lapply(list_of_data, itty_pivot))","code":""},{"path":"/reference/transpose_tibble.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"#' list_2_tib (internal)\n#'\n#' used for diagnose\n#'\n#' @param list_of_data\n#'\n#' @return\n#'\n#' @examples\nlist_2_tib = function(list_of_data)\ndplyr::bind_rows(lapply(list_of_data, itty_pivot)) — transpose_tibble","text":"","code":"transpose_tibble(data)"},{"path":"/reference/transpose_tibble.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"#' list_2_tib (internal)\n#'\n#' used for diagnose\n#'\n#' @param list_of_data\n#'\n#' @return\n#'\n#' @examples\nlist_2_tib = function(list_of_data)\ndplyr::bind_rows(lapply(list_of_data, itty_pivot)) — transpose_tibble","text":"data","code":""},{"path":"/reference/transpose_tibble.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"#' list_2_tib (internal)\n#'\n#' used for diagnose\n#'\n#' @param list_of_data\n#'\n#' @return\n#'\n#' @examples\nlist_2_tib = function(list_of_data)\ndplyr::bind_rows(lapply(list_of_data, itty_pivot)) — transpose_tibble","text":"transpose_tibble (internal) used diagnose","code":""},{"path":[]},{"path":[]},{"path":[]},{"path":"/reference/update_lhs_to_1.html","id":null,"dir":"Reference","previous_headings":"","what":"update_lhs_to_1 (internal to pca_count) — update_lhs_to_1","title":"update_lhs_to_1 (internal to pca_count) — update_lhs_to_1","text":"update_lhs_to_1 (internal pca_count)","code":""},{"path":"/reference/update_lhs_to_1.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"update_lhs_to_1 (internal to pca_count) — update_lhs_to_1","text":"","code":"update_lhs_to_1(formula, quiet = FALSE)"},{"path":"/reference/update_lhs_to_1.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"update_lhs_to_1 (internal to pca_count) — update_lhs_to_1","text":"formula","code":""},{"path":"/reference/varimax_with_pre_rotation.html","id":null,"dir":"Reference","previous_headings":"","what":"varimax_with_pre_rotation (internal to rotate) — varimax_with_pre_rotation","title":"varimax_with_pre_rotation (internal to rotate) — varimax_with_pre_rotation","text":"varimax_with_pre_rotation (internal rotate)","code":""},{"path":"/reference/varimax_with_pre_rotation.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"varimax_with_pre_rotation (internal to rotate) — varimax_with_pre_rotation","text":"","code":"varimax_with_pre_rotation(matrix_to_rotate, pre_rotation)"},{"path":"/reference/varimax_with_pre_rotation.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"varimax_with_pre_rotation (internal to rotate) — varimax_with_pre_rotation","text":"pre_rotation","code":""}]
