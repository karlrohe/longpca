[{"path":"/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"MIT License","title":"MIT License","text":"Copyright (c) 2024 longpca authors Permission hereby granted, free charge, person obtaining copy software associated documentation files (“Software”), deal Software without restriction, including without limitation rights use, copy, modify, merge, publish, distribute, sublicense, /sell copies Software, permit persons Software furnished , subject following conditions: copyright notice permission notice shall included copies substantial portions Software. SOFTWARE PROVIDED “”, WITHOUT WARRANTY KIND, EXPRESS IMPLIED, INCLUDING LIMITED WARRANTIES MERCHANTABILITY, FITNESS PARTICULAR PURPOSE NONINFRINGEMENT. EVENT SHALL AUTHORS COPYRIGHT HOLDERS LIABLE CLAIM, DAMAGES LIABILITY, WHETHER ACTION CONTRACT, TORT OTHERWISE, ARISING , CONNECTION SOFTWARE USE DEALINGS SOFTWARE.","code":""},{"path":"/articles/Intro_to_longpca_with_nycflights_data.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Intro to longpca with nycflights data","text":"’ve already read readme, can skip section PCA nycflights package introduces novel formula syntax PCA. modern applications (data often “long format”), formula syntax helps fluidly imagine PCA without thinking matrices. words, provides layer abstraction matrices. Given formula (long) data, code package transforms data proper format fast PCA via sparse linear algebra. package also provides code 1) help pick number dimensions compute, 2) diagnose suitability PCA (pre post PCA), 3) rotate PCs varimax, 4) visualize interpret dimensions uncovered, (yet) 5) make predictions. package uses “PCA” broad term computing leading singular vectors normalized (sometimes incomplete) matrix. might refer specific instances factor analysis, correspondence analysis, latent symantic analysis, social network analysis, low-rank matrix completion, among possible terms. big-tent PCA, included. longpca development. , functions syntax might change. current approach PCA (principal components analysis) matrix first. note begins explore alternative path, one model first. formula syntax provides alternative way think PCA makes matrices transparent; completely hidden, unless want see code. hope makes PCA legible folks yet learned linear algebra (just like linear models legible without solving linear systems equations). personally inspired approach (despite fact love matrices linear algebra) find model first way thinking much easier direct. document gives illustration data analysis popular nycflights13 data via PCA. Headline: find two seasonal effects (annual weekly) also “fly--zone” (midwest 4ever. ride die <3 much love midwest fam). Code details follow analysis. (Disclaimer: early project. , syntax code likely change great deal. Input welcome ways improve .)","code":""},{"path":"/articles/Intro_to_longpca_with_nycflights_data.html","id":"install","dir":"Articles","previous_headings":"Introduction","what":"Install","title":"Intro to longpca with nycflights data","text":"functions PCA People contained R package longpca. already devtools installed, first need install : Thank Alex Hayes helpful feedback process suggesting name longpca.","code":"install.packages(\"devtools\") devtools::install_github(\"karlrohe/longpca\")"},{"path":"/articles/Intro_to_longpca_with_nycflights_data.html","id":"pca-the-nycflights-","dir":"Articles","previous_headings":"Introduction","what":"PCA the nycflights.","title":"Intro to longpca with nycflights data","text":"illustrate code, consider popular data example nycflights13 contains row every flight departing 3 main New York City airports 2013 (LGA, JFK, EWR). includes things like date, destination, information delays. many matrices “inside” data, don’t think see data. Many applications like . data look like matrix. Instead, looks like spreadsheet SQL database tidy tibble. users often think data. underneath , many possible matrices. code reveal possibilities. first step using longpca function make_interaction_model. requires two arguments, data (tidy data “long format”) formula (explained detail ). Right now, four ways specify model make_interaction_model. Hopefully, can find . Perhaps way? make interaction_model, many things can . running PCA, can diagnose see data “sparse”, , can core find dense core observed data. can also pick_dim estimate large model k data can infer. , introduction, just run PCA right away: performs PCA. key innovation “formula”: ~ (month & day)*(dest), specifies model want. already comfortable matrices SVD, can imagine matrix apply SVD (future, imagined fitting statistical model via least squares). basic syntax formula : outcome ~ unit * context. outcome can left blank (Specification 1 ), otherwise variable data. unit context can variables data, might specified multiple variables data. example, formula ~ (month & day)*(dest), units specified (month & day). next section discusses various ways using formula.","code":"library(nycflights13) flights #> # A tibble: 336,776 × 19 #>     year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time #>    <int> <int> <int>    <int>          <int>     <dbl>    <int>          <int> #>  1  2013     1     1      517            515         2      830            819 #>  2  2013     1     1      533            529         4      850            830 #>  3  2013     1     1      542            540         2      923            850 #>  4  2013     1     1      544            545        -1     1004           1022 #>  5  2013     1     1      554            600        -6      812            837 #>  6  2013     1     1      554            558        -4      740            728 #>  7  2013     1     1      555            600        -5      913            854 #>  8  2013     1     1      557            600        -3      709            723 #>  9  2013     1     1      557            600        -3      838            846 #> 10  2013     1     1      558            600        -2      753            745 #> # ℹ 336,766 more rows #> # ℹ 11 more variables: arr_delay <dbl>, carrier <chr>, flight <int>, #> #   tailnum <chr>, origin <chr>, dest <chr>, air_time <dbl>, distance <dbl>, #> #   hour <dbl>, minute <dbl>, time_hour <dttm> library(nycflights13) im = make_interaction_model(flights, ~ (month & day)*(dest)) pcs = pca(im, k = 6)"},{"path":[]},{"path":"/articles/Intro_to_longpca_with_nycflights_data.html","id":"specification-1-empty-left-side","dir":"Articles","previous_headings":"","what":"Intro to longpca with nycflights data","title":"Intro to longpca with nycflights data","text":"first basic use (perhaps also powerful) specify outcome: ~ (month & day)*(dest). Specification 1 happens left-side formula empty. specifies matrix units (rows) indexed (month & day), two variables flights data, context (columns) indexed destinations dest, outcome (elements matrix) number flights dest (month & day). , 365 rows (one day), 100 columns (one destination), sum elements matrix 336,776, number rows flights data. Said another way, leave left-side empty, counts co-occurrences (month & day) dest makes matrix co-occurrences. people call matrix cross-tab contingency table. PCA matrix counts, folks call Correspondence Analysis.","code":""},{"path":"/articles/Intro_to_longpca_with_nycflights_data.html","id":"specification-2-a-variable-the-left-side-that-counts-something","dir":"Articles","previous_headings":"","what":"Intro to longpca with nycflights data","title":"Intro to longpca with nycflights data","text":"formulation, outcome (left-side formula) variable. example, nycflights13 number seats available plane. can join data flights find number seats available flight. , can use formula, seats ~ (month & day)*dest new data dat make_interaction_model. Specification 2. happens () specify outcome left-hand side formula (ii) use default settings make_interaction_model. formula , units context identical example Specification 1. difference now outcome counts total number seats flew destination, day. fact, Specification 2 similar Specification 1. Imagine flights variable called 1 every element varialbe numeric 1. , formula 1 ~ (month & day)*(dest) interpreted via Specification 2. fact, can type formula without variable 1 data make_interaction_model understand ~ (month & day)*(dest).","code":"dat = flights %>%    select(month, day, dest, tailnum) %>%    left_join(planes %>% select(tailnum, seats)) #> Joining with `by = join_by(tailnum)` im_seats = make_interaction_model(dat, seats ~ (month & day)*dest)"},{"path":"/articles/Intro_to_longpca_with_nycflights_data.html","id":"specification-3-the-outcome-variable-the-thing-on-the-left-side-of-the-formula-should-be-averaged","dir":"Articles","previous_headings":"","what":"Intro to longpca with nycflights data","title":"Intro to longpca with nycflights data","text":"flights data contains column arr_delay gives arrival delay flight. One possible model arr_delay ~ (month & day)*(dest). make sense simply add arrival delays. makes sense average . specified make_interaction_model argument duplicates = \"average\": make_interaction_model(flights, arr_delay ~ (month & day)*(dest), duplicates = \"average\") uses units context last two examples, helpful begin imagining things correspond arrival delays might interact. , build model. example, experience, flights later day likely delayed. Also, weekday flights worse weekend flights. wonder interaction . Specification 3 happens () variable left-hand side formula, (ii) duplicates = \"average\" make_interaction_model, (iii) typically want use pca_na instead pca compute principal components: Often, many () possible combinations (unit, context) pairs appear data. example, flights MSN (Madison, Wisconsin) January 5th. possible combinations appear, say data “sparse”. (can diagnose level sparsity diagnose can look “dense subset” data core). combinations appear data, need decide PCA understand values zero NA. need think problem decide one makes sense. Specifications 1 2, makes sense make missing elements zero sum zero numbers zero. case, use function pca. Specification 3, likely makes sense missing values NA average zero numbers NA. case, call pca_na computes PCs via softImpute::softImpute. Another way specify model (.e. different interaction explore) make unit (day & hour) context dest:","code":"day_dat = flights |>    mutate(day = wday(time_hour, label = TRUE, abbr = FALSE))   im_delays = day_dat |>    select(hour, day , arr_delay) |>    make_interaction_model(arr_delay ~ hour*day,duplicates = \"average\") pc_delays = pca_na(im_delays, k = 3) #> Taking 3 core.  Starting with: #>  20 rows #>  7 columns #>  133 observed values[1] \"adding graph summaries (coreness and connected components).\" #> After taking 3 core.  There remain: #>  19 rows #>  7 columns #>  133 observed values im_dest_delay = day_dat |>    make_interaction_model(arr_delay ~ (day&hour)*dest,duplicates = \"average\")"},{"path":"/articles/Intro_to_longpca_with_nycflights_data.html","id":"specification-4-the-variable-after-the-is-a-text-field-or-a-sequence-that-needs-to-be-parsed","dir":"Articles","previous_headings":"","what":"Intro to longpca with nycflights data","title":"Intro to longpca with nycflights data","text":"good motivating examples Specification 4 flights data. Instead, please see parse_text vignette. can access functionality argument parse_text = TRUE inside make_interaction_model.","code":""},{"path":"/articles/Intro_to_longpca_with_nycflights_data.html","id":"what-is-inside-the-output-of-pca","dir":"Articles","previous_headings":"","what":"What is inside the output of pca","title":"Intro to longpca with nycflights data","text":"output pca (pca_na) contains pc’s loadings tidy format: tidy, makes pretty easy ggplot. First, let’s units (.e. dates/rows). interpret PC’s, best plot native space. dates, native space time series sequence. Let’s plot . give interpretation plots.  always think first PC “mean”. see flights less constant throughout year (see y-axis). presume oscillations weekends. pc_1 says , across destinations, flights work week fewer flights weekends. second pc gives seasonal effect (fewer flights winter, summer); importantly, pc_1, destinations negative values (.e. winter, fewer summer). third pc positive weekend destinations (flights weekends fewer weekdays relative pc_1). , like pc_2 destinations negative value (.e. flights weekends fewer weekdays relative previous two pc’s). last three harder interpret. uninformed guess artifact airline decisions. guess, ’d love hear . Also, later pick_dim, evidence noise. Now, let’s columns (.e. destinations). “native space” destinations map. Let’s plot . sure maps installed.  pc_1 align larger smaller airports (bigger airports <-> flights throughout year). pc_2 negative Denver Florida positive Maine. Looking back time series plots, interpret mean people go Denver (skiing) Florida (beach) winter Maine (coastline) summer. pc_3 picks “fly-zone”… looking back time series, folks prefer travel work week. , blue areas weekend (vacation) destinations red areas fly-. pc’s difficult interpret (guess weird artifacts airline things… noise). see last three heavily localized airports, looking back pairs plots can see localization. Given , sense interesting, needed make sense , print extreme elements dig airports. Making function todo item. , using code easy. just need specify formula. ’s fun think combinations easy try . three functions might like diagnose, pick_dim, plot explained .","code":"im = make_interaction_model(flights, ~ (month & day)*(dest)) pcs = pca(im, k = 6)   pcs$row_features %>% sample_n(size = 3) #> # A tibble: 3 × 12 #>   month   day     n row_num degree weighted_degree pc_1_rows pc_2_rows pc_3_rows #>   <int> <int> <int>   <int>  <int>           <dbl>     <dbl>     <dbl>     <dbl> #> 1    10    23   975     143     84             975      1.03    -1.02    0.684   #> 2     3    20   970     161     83             970      1.03     1.28    1.17    #> 3     8    26   982     109     87             982      1.03    -0.827   0.00865 #> # ℹ 3 more variables: pc_4_rows <dbl>, pc_5_rows <dbl>, pc_6_rows <dbl> pcs$column_features %>% sample_n(size = 3) #> # A tibble: 3 × 11 #>   dest      n col_num degree weighted_degree pc_1_columns pc_2_columns #>   <chr> <int>   <int>  <int>           <dbl>        <dbl>        <dbl> #> 1 LEX       1     104      1               1      0.00135     -0.00124 #> 2 MKE    2802      35    365            2802      0.935       -0.0786  #> 3 BWI    1781      48    365            1781      0.726        1.94    #> # ℹ 4 more variables: pc_3_columns <dbl>, pc_4_columns <dbl>, #> #   pc_5_columns <dbl>, pc_6_columns <dbl> im = make_interaction_model(flights, ~ (month & day)*(dest)) pcs = pca(im, k = 6)  pcs$row_features %>%    mutate(date = make_date(day = day, month=month, year = 2013)) %>%    select(date, contains(\"pc_\")) %>%    pivot_longer(contains(\"pc_\"), names_to = \"pc_dimension\", values_to = \"loadings\") %>%    ggplot(aes(x = date, y = loadings)) + geom_line() +    facet_wrap(~pc_dimension, scales= \"free\") + geom_smooth() #> `geom_smooth()` using method = 'loess' and formula = 'y ~ x' airports %>% sample_n(size = 3) #> # A tibble: 3 × 8 #>   faa   name                            lat   lon   alt    tz dst   tzone        #>   <chr> <chr>                         <dbl> <dbl> <dbl> <dbl> <chr> <chr>        #> 1 09J   Jekyll Island Airport          31.1 -81.4    11    -5 A     America/New… #> 2 GTB   Wheeler Sack Aaf               44.1 -75.7   690    -5 A     America/New… #> 3 MTH   Florida Keys Marathon Airport  24.7 -81.1     7    -5 A     America/New…  # first, get the lat and lon for the airports: airport_dat = pcs$column_features %>%    left_join(airports %>% select(dest=faa, lat,lon)) %>%    select(lat, lon, contains(\"_col\")) %>%    pivot_longer(contains(\"pc_\"),                names_to = \"pc_dimension\", values_to = \"loadings\") %>%    drop_na() #> Joining with `by = join_by(dest)`   library(maps) usa_map <- map_data(\"state\") p <- ggplot() +    geom_polygon(data = usa_map, aes(x = long, y = lat, group = group),                 fill = \"white\", color = \"black\") +   coord_fixed(1.3, xlim = c(-125, -65), ylim = c(25, 50))  # i'm only keeping lower 48 states, dropping Anchorage and Honolulu.   p + geom_point(data = airport_dat, aes(x = lon, y = lat,                                         size = abs(loadings), color = loadings)) +   facet_wrap(~ pc_dimension)  +   scale_color_gradient2(low = \"red\", high = \"blue\", mid = \"white\")"},{"path":[]},{"path":"/articles/Intro_to_longpca_with_nycflights_data.html","id":"what-is-an-interaction_model","dir":"Articles","previous_headings":"A deeper look inside the code.","what":"What is an interaction_model?","title":"Intro to longpca with nycflights data","text":"make maximum use package, helpful think models, matrices. key functions package handling class interaction_model: im list four elements. First, $interaction_tibble can thought sparse matrix triplet form; get_Matrix(im) uses construct sparse matrix. , $row_universe $column_universe can thought holding information corresponding row/column. Finally, $settings contains various details construction.","code":"formula = ~ (month & day)*dest im = make_interaction_model(flights, formula) class(im) #> [1] \"interaction_model\" names(im) #> [1] \"interaction_tibble\" \"row_universe\"       \"column_universe\"    #> [4] \"settings\""},{"path":[]},{"path":"/articles/Intro_to_longpca_with_nycflights_data.html","id":"examining-the-matrix-sparsity","dir":"Articles","previous_headings":"Let’s do a more careful analysis","what":"Examining the matrix sparsity","title":"Intro to longpca with nycflights data","text":"package contains helper functions. First, lots rows columns non-zero elements, can cause “localization issues”. matrix needs “dense enough” PCA find good stuff. , diagnose prints simple diagnostics plots “degree distribution” rows columns. , “degree” number non-zero elements row column.  example, either average degree less 10, might worried. Another diagnostic print percent_le_x gives percent rows/columns row/col sums less equal x. majority rows columns degree less equal 3, worried. clues matrix sparse might trouble. Issues sparsity likely manifest localization; something evaluated functions . One possibility take “core”:  finds largest subset rows columns row column least core_threshold = 3 data points (also return largest connected component). case, discards two destination airports, LEX LGA:","code":"# inspect \"degree distributions\" with this funciton: #  recall that im is the interaction_model defined above. diagnose(im) #> # A tibble: 6 × 3 #>   measurement      dest `month & day` #>   <chr>           <dbl>         <dbl> #> 1 number_of_items   105           365 #> 2 average_degree    297            86 #> 3 median_degree     365            86 #> 4 percent_le_1        2             0 #> 5 percent_le_2        2             0 #> 6 percent_le_3        2             0 im_cored = core(im,core_threshold = 3) #> [1] \"adding graph summaries (coreness and connected components).\" nrow(im$column_universe) #> [1] 105 nrow(im_cored$column_universe) #> [1] 103 diagnose(im_cored) #> Warning in scale_y_log10(): log-10 transformation introduced #> infinite values. #> Warning: Removed 27 rows containing missing values or values outside the scale range #> (`geom_bar()`). #> # A tibble: 6 × 3 #>   measurement      dest `month & day` #>   <chr>           <dbl>         <dbl> #> 1 number_of_items   103           365 #> 2 average_degree    303            86 #> 3 median_degree     365            86 #> 4 percent_le_1        0             0 #> 5 percent_le_2        0             0 #> 6 percent_le_3        0             0 im$column_universe |> anti_join(im_cored$column_universe, by = \"dest\") #> # A tibble: 2 × 3 #>   dest      n col_num #>   <chr> <int>   <int> #> 1 LEX       1     104 #> 2 LGA       1     105"},{"path":"/articles/Intro_to_longpca_with_nycflights_data.html","id":"picking-k-with-cross-validated-eigenvalues","dir":"Articles","previous_headings":"Let’s do a more careful analysis","what":"Picking k with cross-validated eigenvalues","title":"Intro to longpca with nycflights data","text":"PCA, need pick model size \\(k\\). way lab cross-validated eigenvalues. gives Z-score p-value. arxiv paper. Alex Hayes Fan Chen made proper R package CRAN gdim. example, picks k=4.  Notice top-line printout says estimated graph dimension 4. , use k=6 see example become harder interpret. expect just noise… also, maybe just noise?","code":"cv_eigs = pick_dim(im, dimMax = 10,num_bootstraps = 5)  plot(cv_eigs) cv_eigs #> Estimated graph dimension:    4 #>  #> Number of bootstraps:         5 #> Edge splitting probabaility:  0.1 #> Significance level:       0.05 #>  #>  ------------ Summary of Tests ------------ #>   k           z        pvals         padj #>   1 166.9096296 0.000000e+00 0.000000e+00 #>   2  12.5328707 2.467185e-36 2.467185e-36 #>   3   8.7270943 1.306496e-18 1.306496e-18 #>   4   4.7824034 8.660580e-07 8.660580e-07 #>   5   0.6311604 2.639678e-01 2.639678e-01 #>   6  -2.8350333 9.977090e-01 9.977090e-01 #>   7  -5.9380729 1.000000e+00 1.000000e+00 #>   8  -6.0137710 1.000000e+00 1.000000e+00 #>   9  -7.7210977 1.000000e+00 1.000000e+00 #>  10  -7.6142011 1.000000e+00 1.000000e+00"},{"path":"/articles/Intro_to_longpca_with_nycflights_data.html","id":"lets-get-the-people-some-pca","dir":"Articles","previous_headings":"Let’s do a more careful analysis","what":"Let’s get the people some PCA","title":"Intro to longpca with nycflights data","text":"right now, default make_interaction_model multiple rows long data values (month & day) also dest, value inside matrix sum values left hand side formula. variable specified left hand side, like imagining additional column data, 1, value 1 every row. , formula = ~ (month & day)*(dest) equivalent formula = 1 ~ (month & day)*(dest). summing outcomes, 1, counts many times entry appears. count, variance stabilizing transformation Poisson square root, default code pca square root count. , code computes normalized regularized Laplacian L (using number non-zero entries degree). , computes leading k singular vectors. done sparse linear algebra via packages Matrix irlba. row_features column_features PC’s loadings (don’t prefer old terms). middle_B gives singular values. settings contains details handy later functions. Notice features wide tidy form, making easy lubridate::make_date (row_features) left-join airports (get latitude longitude) column_features.","code":"pcs = pca(im, k = 6) names(pcs) #> [1] \"row_features\"    \"column_features\" \"middle_B\"        \"settings\" sample_n(pcs$row_features, size = 3) #> # A tibble: 3 × 12 #>   month   day     n row_num degree weighted_degree pc_1_rows pc_2_rows pc_3_rows #>   <int> <int> <int>   <int>  <int>           <dbl>     <dbl>     <dbl>     <dbl> #> 1     4    23   965     177     82             965     1.04      0.146  -0.671   #> 2     6    26   995      40     88             995     1.04     -0.719  -0.00845 #> 3     6    22   812     307     88             812     0.928    -0.368   2.24    #> # ℹ 3 more variables: pc_4_rows <dbl>, pc_5_rows <dbl>, pc_6_rows <dbl> sample_n(pcs$column_features, size=3) #> # A tibble: 3 × 11 #>   dest      n col_num degree weighted_degree pc_1_columns pc_2_columns #>   <chr> <int>   <int>  <int>           <dbl>        <dbl>        <dbl> #> 1 EYW      17      99     17              17       0.0215        0.423 #> 2 SDF    1157      56    365            1157       0.596        -0.526 #> 3 HDN      15     100     15              15       0.0183        0.612 #> # ℹ 4 more variables: pc_3_columns <dbl>, pc_4_columns <dbl>, #> #   pc_5_columns <dbl>, pc_6_columns <dbl>"},{"path":"/articles/Intro_to_longpca_with_nycflights_data.html","id":"diagnostic-plots","dir":"Articles","previous_headings":"","what":"Intro to longpca with nycflights data","title":"Intro to longpca with nycflights data","text":"can plot(pcs). makes five plots, described plots displayed.      five plots: Screeplot: top k singular values L. Better screeplot: singular values 2:k (first one usually dominant difficult see elbow past ). “localization plot” similar (maybe exact?) stuff; row (column) compute degree leverage score. Take log . Fit linear model log(leverage)~log(degree) plot residuals log(degree). localization, suspect big curl right side. Pairs plot row_features. plot emphasized varimax paper. example plots , see clear radial streaks. pairs plot column_features. pairs plots, 1000 points, code samples 1000 points probability proportional leverage scores. plot k=10 dimensions. k larger, plots first 5 last 5.","code":"plot(pcs) #> Press [Enter] to continue to the next plot... #> Press [Enter] to continue to the next plot... #> `geom_smooth()` using formula = 'y ~ s(x, bs = \"cs\")' #> Press [Enter] to continue to the next plot... #> Press [Enter] to continue to the next plot..."},{"path":"/articles/parse_text.html","id":"specification-4-parsing-text-","dir":"Articles","previous_headings":"","what":"Specification 4: parsing text.","title":"parse_text inside longpca","text":"flights data, variable dest 105 unique values. serve context_id’s formula ~ (month & day)*dest. Sometimes, variable data contains free text, sequences words. case, need first parse/extract context_id’s (e.g. words/bi-grams/etc). example, loaded longpca toy data set all_packages. 20000 rows. row gives information one R package. Notice column Imports gives “csv” packages. can “parse” values parse_text = TRUE: hood, make_interaction_model(..., parse_text = TRUE) calls tidytext::unnest_tokens parse variable *. case, converts Imports “bag--words”. also converts every letter lower case removes punctuation. , columns im_imports indexed unique packages imported. 20,319 total Packages all_packages one forms “row” im_imports. 6,230 packages imported another package. forms “column” im_imports. “row” “column” quotes im_imports matrix, matrix “hood” rows columns. Additional arguments make_interaction_model passed tidytext::unest_tokens. example, default puts imported packages lower case. can turn … Notice Rcpp row 6 $column_universe previously rcpp (lower case). parse different variable instead. example,  see stopwords. form high degree nodes interaction_model graph. factor loads heavily often factor indicates “document length”. Alternatively, can remove stop words like : can also parse multiple columns &: , let’s quick analysis. see tokens sparse, 64% tokens appearing ! want keep eye localization streaks plot.  sparse, function core can used pull densely connected core data. particular, treats interaction_model object bipartite graph, finds k-core largest connected component.  can identify largest statistically reasonable choice k using pick_dim uses cross-validated eigenvalues implimented package gdim (github).  ’m going pick 10 convenience.     Let’s use","code":"# you can get a fresh version here: # all_packages = available.packages() %>% as_tibble() all_packages |> select(Package,  Imports) #> # A tibble: 20,319 × 2 #>    Package       Imports                               #>    <chr>         <chr>                                 #>  1 A3            NA                                    #>  2 AalenJohansen NA                                    #>  3 AATtools      magrittr, dplyr, doParallel, foreach  #>  4 ABACUS        ggplot2 (>= 3.1.0), shiny (>= 1.3.1), #>  5 abasequence   NA                                    #>  6 abbreviate    NA                                    #>  7 abc           NA                                    #>  8 abc.data      NA                                    #>  9 ABC.RAP       graphics, stats, utils                #> 10 ABCanalysis   plotrix                               #> # ℹ 20,309 more rows im_imports = make_interaction_model(all_packages, ~Package*Imports, parse_text= TRUE) im_imports$row_universe #> # A tibble: 20,319 × 3 #>    Package                n row_num #>    <chr>              <int>   <int> #>  1 Seurat                64       1 #>  2 tidyverse             60       2 #>  3 radiant.data          58       3 #>  4 radiant.model         58       4 #>  5 SSDM                  55       5 #>  6 BasketballAnalyzeR    53       6 #>  7 tRigon                49       7 #>  8 AFM                   48       8 #>  9 dextergui             48       9 #> 10 proteus               48      10 #> # ℹ 20,309 more rows im_imports$column_universe #> # A tibble: 6,230 × 4 #>    from_text token        n col_num #>    <chr>     <chr>    <int>   <int> #>  1 Imports   stats     5442       1 #>  2 Imports   utils     3423       2 #>  3 Imports   dplyr     3299       3 #>  4 Imports   methods   3210       4 #>  5 Imports   ggplot2   3135       5 #>  6 Imports   rcpp      2548       6 #>  7 Imports   rlang     2172       7 #>  8 Imports   graphics  2158       8 #>  9 Imports   magrittr  1954       9 #> 10 Imports   stringr   1698      10 #> # ℹ 6,220 more rows im_imports = make_interaction_model(all_packages, ~Package*Imports, parse_text= TRUE, to_lower = FALSE) im_imports$column_universe #> # A tibble: 6,230 × 4 #>    from_text token        n col_num #>    <chr>     <chr>    <int>   <int> #>  1 Imports   stats     5442       1 #>  2 Imports   utils     3423       2 #>  3 Imports   dplyr     3299       3 #>  4 Imports   methods   3210       4 #>  5 Imports   ggplot2   3135       5 #>  6 Imports   Rcpp      2548       6 #>  7 Imports   rlang     2172       7 #>  8 Imports   graphics  2158       8 #>  9 Imports   magrittr  1954       9 #> 10 Imports   stringr   1698      10 #> # ℹ 6,220 more rows im_text = make_interaction_model(top_packages,~Package*Description,  parse_text = TRUE, to_lower= TRUE) diagnose(im_text) #> Warning in scale_y_log10(): log-10 transformation introduced #> infinite values. #> Warning: Removed 7 rows containing missing values or values outside the scale range #> (`geom_bar()`). #> # A tibble: 6 × 3 #>   measurement     Package `from_text & token` #>   <chr>             <dbl>               <dbl> #> 1 number_of_items    1094                7878 #> 2 average_degree       38                   5 #> 3 median_degree        33                   1 #> 4 percent_le_1          0                  57 #> 5 percent_le_2          0                  71 #> 6 percent_le_3          0                  77 im_text$column_universe |> arrange(desc(n)) #> # A tibble: 7,878 × 4 #>    from_text   token         n col_num #>    <chr>       <chr>     <int>   <int> #>  1 Description and        2571       1 #>  2 Description the        1999       2 #>  3 Description of         1388       3 #>  4 Description for        1350       4 #>  5 Description to         1104       5 #>  6 Description a          1013       6 #>  7 Description in          722       7 #>  8 Description functions   581       8 #>  9 Description data        541       9 #> 10 Description package     515      10 #> # ℹ 7,868 more rows # remove stop words by removing them from the column_universe, #  then use the function subset_im to renumber the columns/rows and remove any lines from interaction_tibble im_text$column_universe = im_text$column_universe |>    anti_join(tidytext::stop_words, by = c(\"token\"=\"word\")) im_text = im_text |> subset_im() # inspect the new column_universe to see that the stop words have been removed.  im_text$column_universe |> arrange(desc(n)) #> # A tibble: 7,435 × 4 #>    from_text   token         n col_num #>    <chr>       <chr>     <int>   <int> #>  1 Description functions   581       1 #>  2 Description data        541       2 #>  3 Description package     515       3 #>  4 Description models      319       4 #>  5 Description doi         285       5 #>  6 Description methods     226       6 #>  7 Description analysis    218       7 #>  8 Description function    164       8 #>  9 Description model       155       9 #> 10 Description based       142      10 #> # ℹ 7,425 more rows im_imports_authors = make_interaction_model(top_packages, ~Package*(Imports&Author&Description&Title), parse_text = TRUE) im_imports_authors$row_universe #> # A tibble: 1,094 × 3 #>    Package             n row_num #>    <chr>           <int>   <int> #>  1 broom             671       1 #>  2 DescTools         562       2 #>  3 ff                488       3 #>  4 knitr             430       4 #>  5 ape               411       5 #>  6 spatstat          392       6 #>  7 spdep             381       7 #>  8 netmeta           346       8 #>  9 Seurat            339       9 #> 10 spatstat.linnet   333      10 #> # ℹ 1,084 more rows im_imports_authors$column_universe #> # A tibble: 17,696 × 4 #>    from_text   token         n col_num #>    <chr>       <chr>     <int>   <int> #>  1 Author      ctb        2744       1 #>  2 Description and        2571       2 #>  3 Author      aut        2077       3 #>  4 Description the        1999       4 #>  5 Description of         1388       5 #>  6 Description for        1350       6 #>  7 Description to         1104       7 #>  8 Author      https      1048       8 #>  9 Description a          1013       9 #> 10 Author      orcid.org  1008      10 #> # ℹ 17,686 more rows diagnose(im_imports_authors) #> Warning in scale_y_log10(): log-10 transformation introduced #> infinite values. #> Warning: Removed 5 rows containing missing values or values outside the scale range #> (`geom_bar()`). #> # A tibble: 6 × 3 #>   measurement     Package `from_text & token` #>   <chr>             <dbl>               <dbl> #> 1 number_of_items    1094               17696 #> 2 average_degree       70                   4 #> 3 median_degree        62                   1 #> 4 percent_le_1          0                  60 #> 5 percent_le_2          0                  75 #> 6 percent_le_3          0                  81 # you can remove these words that appear less than 5 times (and documents that have less than 5 words) via: im_text = core(im_text, core_threshold = 5) #> [1] \"adding graph summaries (coreness and connected components).\" diagnose(im_text) #> Warning in scale_y_log10(): log-10 transformation introduced #> infinite values. #> Warning: Removed 8 rows containing missing values or values outside the scale range #> (`geom_bar()`). #> # A tibble: 6 × 3 #>   measurement     Package `from_text & token` #>   <chr>             <dbl>               <dbl> #> 1 number_of_items    1002                1188 #> 2 average_degree       18                  15 #> 3 median_degree        15                   9 #> 4 percent_le_1          0                   0 #> 5 percent_le_2          0                   0 #> 6 percent_le_3          0                   0 eigcv = pick_dim(im_imports_authors, num_bootstraps = 20) plot(eigcv) eigcv #> Estimated graph dimension:    20 #>  #> Number of bootstraps:         20 #> Edge splitting probabaility:  0.1 #> Significance level:       0.05 #>  #>  ------------ Summary of Tests ------------ #>   k         z        pvals         padj #>   1 52.485295 0.000000e+00 0.000000e+00 #>   2 11.238153 1.324323e-29 1.324323e-29 #>   3  6.928938 2.120063e-12 2.120063e-12 #>   4 18.267156 7.556182e-75 7.556182e-75 #>   5 11.858499 9.721468e-33 9.721468e-33 #>   6  5.716077 5.450576e-09 5.450576e-09 #>   7  5.689208 6.381499e-09 6.381499e-09 #>   8  7.313266 1.303634e-13 1.303634e-13 #>   9  7.949433 9.368327e-16 9.368327e-16 #>  10  9.502129 1.028216e-21 1.028216e-21 #>  11  9.000204 1.126495e-19 1.126495e-19 #>  12  6.834819 4.105421e-12 4.105421e-12 #>  13  4.717907 1.191416e-06 1.191416e-06 #>  14  6.710736 9.682262e-12 9.682262e-12 #>  15  7.593119 1.561483e-14 1.561483e-14 #>  16  8.220860 1.010248e-16 1.010248e-16 #>  17  8.542267 6.580719e-18 6.580719e-18 #>  18  8.822639 5.589641e-19 5.589641e-19 #>  19  8.112027 2.489107e-16 2.489107e-16 #>  20  7.331145 1.140971e-13 1.140971e-13 pcs = pca(im_imports_authors, k = 10) streaks(pcs) streaks(pcs, \"columns\") spcs = rotate(pcs) streaks(spcs) streaks(spcs, \"columns\") im = make_interaction_model(all_packages, ~Package*Imports, parse_text = TRUE, to_lower = FALSE) pcs = im |> core() |> pca(10) #> [1] \"adding graph summaries (coreness and connected components).\" im_text = make_interaction_model(top_packages, ~Package*(Title & Description), parse_text= TRUE) im_text$column_universe = im_text$column_universe |> dplyr::anti_join(tidytext::stop_words, by = c(\"token\"=\"word\")) im_text = im_text |> subset_im() |> core() #> [1] \"adding graph summaries (coreness and connected components).\" bff(pcs, im_text, num_best = 4) #> # A tibble: 0 × 1 #> # ℹ 1 variable: factor <chr>"},{"path":"/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Rohe Karl. Author, maintainer.","code":""},{"path":"/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Karl R (2024). longpca: formula interface model-first PCA; PCA people!. R package version 0.0.0.9000, https://github.com/karlrohe/longpca.","code":"@Manual{,   title = {longpca: A formula interface for model-first PCA; PCA for the people!},   author = {Rohe Karl},   year = {2024},   note = {R package version 0.0.0.9000},   url = {https://github.com/karlrohe/longpca}, }"},{"path":"/index.html","id":"pca-for-the-people","dir":"","previous_headings":"","what":"A formula interface for model-first PCA; PCA for the people!","title":"A formula interface for model-first PCA; PCA for the people!","text":"Karl Rohe 2024-01-03 package introduces novel formula syntax PCA. modern applications (data often “long format”), formula syntax helps fluidly imagine PCA without thinking matrices. words, provides layer abstraction matrices. Given formula (long) data, code package transforms data proper format fast PCA via sparse linear algebra. package also provides code 1) help pick number dimensions compute, 2) diagnose suitability PCA (pre post PCA), 3) rotate PCs varimax, 4) visualize interpret dimensions uncovered, (yet) 5) make predictions. package uses “PCA” broad term computing leading singular vectors normalized (sometimes incomplete) matrix. might refer specific instances factor analysis, correspondence analysis, latent symantic analysis, social network analysis, low-rank matrix completion, among possible terms. big-tent PCA, included. longpca development. , functions syntax might change. current approach PCA (principal components analysis) matrix first. note begins explore alternative path, one model first. formula syntax provides alternative way think PCA makes matrices transparent; completely hidden, unless want see code. hope makes PCA legible folks yet learned linear algebra (just like linear models legible without solving linear systems equations). personally inspired approach (despite fact love matrices linear algebra) find model first way thinking much easier direct. document gives illustration data analysis popular nycflights13 data via PCA. Headline: find two seasonal effects (annual weekly) also “fly--zone” (midwest 4ever. ride die <3 much love midwest fam). Code details follow analysis. (Disclaimer: early project. , syntax code likely change great deal. Input welcome ways improve .)","code":""},{"path":"/index.html","id":"install","dir":"","previous_headings":"","what":"Install","title":"A formula interface for model-first PCA; PCA for the people!","text":"functions PCA People contained R package longpca. already devtools installed, first need install : Thank Alex Hayes helpful feedback process suggesting name longpca.","code":"install.packages(\"devtools\") devtools::install_github(\"karlrohe/longpca\")"},{"path":"/index.html","id":"pca-the-nycflights","dir":"","previous_headings":"","what":"PCA the nycflights.","title":"A formula interface for model-first PCA; PCA for the people!","text":"code fast nimble. First define “model” formula… data: three functions run im: diagnose, pick_dim, pca. three key functions run pcs: plot, rotate, top. See vignettes illustrations: depth example nycflights13 data Inside make_interaction_model, can parse_text","code":"formula = 1 ~ (month & day)*(dest) im = make_interaction_model(flights, formula) pcs = pca(im, k = 6)"},{"path":"/index.html","id":"slightly-more-detail","dir":"","previous_headings":"PCA the nycflights.","what":"Slightly more detail…","title":"A formula interface for model-first PCA; PCA for the people!","text":"hope model first PCA formula makes interacting matrix / linear algebra unnecessary. said, might instructive understand class interaction_model see represents matrix “hood”. function make_interaction_model constructs list class interaction_model. can think abstraction matrix… “matrix like thing,” month & day index rows dest indexes columns. month & day come interaction * formula dest comes afterwords. , “matrix” sparse triplet form: reason actually wanted sparse Matrix… hope model first PCA interaction_model makes data analysis direct, .e. need think matrix (much). Instead, path simply way estimate “low rank” statistical model via least squares.","code":"formula = 1 ~ (month & day)*(dest) im = make_interaction_model(flights,formula) names(im) ## [1] \"interaction_tibble\" \"row_universe\"       \"column_universe\"    ## [4] \"settings\" class(im) ## [1] \"interaction_model\" im$row_universe ## # A tibble: 365 × 4 ##    month   day     n row_num ##    <int> <int> <int>   <int> ##  1    11    27  1014       1 ##  2     7    11  1006       2 ##  3     7     8  1004       3 ##  4     7    10  1004       4 ##  5    12     2  1004       5 ##  6     7    18  1003       6 ##  7     7    25  1003       7 ##  8     7    12  1002       8 ##  9     7     9  1001       9 ## 10     7    17  1001      10 ## # ℹ 355 more rows im$column_universe ## # A tibble: 105 × 3 ##    dest      n col_num ##    <chr> <int>   <int> ##  1 ORD   17283       1 ##  2 ATL   17215       2 ##  3 LAX   16174       3 ##  4 BOS   15508       4 ##  5 MCO   14082       5 ##  6 CLT   14064       6 ##  7 SFO   13331       7 ##  8 FLL   12055       8 ##  9 MIA   11728       9 ## 10 DCA    9705      10 ## # ℹ 95 more rows im$interaction_tibble ## # A tibble: 31,229 × 3 ##    row_num col_num outcome ##      <int>   <int>   <dbl> ##  1       1       1      52 ##  2       1       2      51 ##  3       1       3      49 ##  4       1       4      43 ##  5       1       5      40 ##  6       1       6      42 ##  7       1       7      43 ##  8       1       8      38 ##  9       1       9      37 ## 10       1      10      28 ## # ℹ 31,219 more rows A = get_Matrix(im, import_names = TRUE) str(A) ## Formal class 'dgCMatrix' [package \"Matrix\"] with 6 slots ##   ..@ i       : int [1:31229] 0 1 2 3 4 5 6 7 8 9 ... ##   ..@ p       : int [1:106] 0 365 730 1095 1460 1825 2190 2555 2920 3285 ... ##   ..@ Dim     : int [1:2] 365 105 ##   ..@ Dimnames:List of 2 ##   .. ..$ : chr [1:365] \"11/27\" \"7/11\" \"7/8\" \"7/10\" ... ##   .. ..$ : chr [1:105] \"ORD\" \"ATL\" \"LAX\" \"BOS\" ... ##   ..@ x       : num [1:31229] 52 55 55 55 49 54 55 55 54 55 ... ##   ..@ factors : list()"},{"path":"/reference/add_bipartite_summaries.html","id":null,"dir":"Reference","previous_headings":"","what":"add_bipartite_summaries\nthis function takes an interaction_model and  an interaction_model, where row_universe and column_universe have two additional columns $coreness and $component_label. importantly, strange behavior if im is a symmetric graph. this treats each row index and each column index as nodes in a graph.  So, if something appears in both rows and columns (e.g. as in symmetric graph), then this will be ignored. — add_bipartite_summaries","title":"add_bipartite_summaries\nthis function takes an interaction_model and  an interaction_model, where row_universe and column_universe have two additional columns $coreness and $component_label. importantly, strange behavior if im is a symmetric graph. this treats each row index and each column index as nodes in a graph.  So, if something appears in both rows and columns (e.g. as in symmetric graph), then this will be ignored. — add_bipartite_summaries","text":"add_bipartite_summaries function takes interaction_model  interaction_model, row_universe column_universe two additional columns $coreness $component_label. importantly, strange behavior im symmetric graph. treats row index column index nodes graph.  , something appears rows columns (e.g. symmetric graph), ignored.","code":""},{"path":"/reference/add_bipartite_summaries.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"add_bipartite_summaries\nthis function takes an interaction_model and  an interaction_model, where row_universe and column_universe have two additional columns $coreness and $component_label. importantly, strange behavior if im is a symmetric graph. this treats each row index and each column index as nodes in a graph.  So, if something appears in both rows and columns (e.g. as in symmetric graph), then this will be ignored. — add_bipartite_summaries","text":"","code":"add_bipartite_summaries(im_input)"},{"path":"/reference/add_bipartite_summaries.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"add_bipartite_summaries\nthis function takes an interaction_model and  an interaction_model, where row_universe and column_universe have two additional columns $coreness and $component_label. importantly, strange behavior if im is a symmetric graph. this treats each row index and each column index as nodes in a graph.  So, if something appears in both rows and columns (e.g. as in symmetric graph), then this will be ignored. — add_bipartite_summaries","text":"im","code":""},{"path":"/reference/add_graph_summaries.html","id":null,"dir":"Reference","previous_headings":"","what":"Add Graph Summaries to interaction_model — add_graph_summaries","title":"Add Graph Summaries to interaction_model — add_graph_summaries","text":"function computes graph summaries coreness, connected components, personalized PageRank interaction_model. adds summaries row column universes input interaction_model.","code":""},{"path":"/reference/add_graph_summaries.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Add Graph Summaries to interaction_model — add_graph_summaries","text":"","code":"add_graph_summaries(   im_input,   row_key = NULL,   col_key = NULL,   tib_with_weights = NULL )"},{"path":"/reference/add_graph_summaries.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Add Graph Summaries to interaction_model — add_graph_summaries","text":"im_input interaction_model object containing interaction tibble, row universe, column universe. row_key column name row universe corresponds node names graph. col_key column name column universe corresponds node names graph. tib_with_weights tibble containing node weights personalized PageRank calculation.","code":""},{"path":"/reference/add_graph_summaries.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Add Graph Summaries to interaction_model — add_graph_summaries","text":"input interaction_model object added graph summaries row column universes.","code":""},{"path":"/reference/add_graph_summaries.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Add Graph Summaries to interaction_model — add_graph_summaries","text":"","code":"im = make_interaction_model(all_packages, ~Package*Imports, parse_text = TRUE, to_lower = FALSE) row_key = \"Package\" col_key = \"token\" tib_with_weights = all_packages |> dplyr::mutate(weights = nchar(Package)) |> dplyr::select(Package, weights) add_graph_summaries(im, row_key, col_key, tib_with_weights) #> Error in add_graph_summaries(im, row_key, col_key, tib_with_weights): object 'im' not found"},{"path":"/reference/bff.html","id":null,"dir":"Reference","previous_headings":"","what":"Best Feature Function (bff)\nGiven a pc object from pca, or a rotated version, we wish to interpret the individual dimensions. Often, each unit/row (or context/column) of the original interaction_model will have a some sort of text description.  For example, if each row is an R package, we have the package title and description. Convert these text descriptions into an interaction_model where the units (i.e. the variable before the *) matches either the units or context for the pc. — bff","title":"Best Feature Function (bff)\nGiven a pc object from pca, or a rotated version, we wish to interpret the individual dimensions. Often, each unit/row (or context/column) of the original interaction_model will have a some sort of text description.  For example, if each row is an R package, we have the package title and description. Convert these text descriptions into an interaction_model where the units (i.e. the variable before the *) matches either the units or context for the pc. — bff","text":"function bff takes pc object, interaction_model.  ","code":""},{"path":"/reference/bff.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Best Feature Function (bff)\nGiven a pc object from pca, or a rotated version, we wish to interpret the individual dimensions. Often, each unit/row (or context/column) of the original interaction_model will have a some sort of text description.  For example, if each row is an R package, we have the package title and description. Convert these text descriptions into an interaction_model where the units (i.e. the variable before the *) matches either the units or context for the pc. — bff","text":"","code":"bff(pcs, im_text, num_best = 10)"},{"path":"/reference/bff.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Best Feature Function (bff)\nGiven a pc object from pca, or a rotated version, we wish to interpret the individual dimensions. Often, each unit/row (or context/column) of the original interaction_model will have a some sort of text description.  For example, if each row is an R package, we have the package title and description. Convert these text descriptions into an interaction_model where the units (i.e. the variable before the *) matches either the units or context for the pc. — bff","text":"num_best","code":""},{"path":"/reference/bff.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Best Feature Function (bff)\nGiven a pc object from pca, or a rotated version, we wish to interpret the individual dimensions. Often, each unit/row (or context/column) of the original interaction_model will have a some sort of text description.  For example, if each row is an R package, we have the package title and description. Convert these text descriptions into an interaction_model where the units (i.e. the variable before the *) matches either the units or context for the pc. — bff","text":"","code":"im = make_interaction_model(all_packages, ~Package*Imports, parse_text = TRUE, to_lower = FALSE) pcs = im |> pca(10) im_text = make_interaction_model(top_packages, ~Package*(Title & Description), parse_text= TRUE) im_text$column_universe = im_text$column_universe |> dplyr::anti_join(tidytext::stop_words, by = c(\"token\"=\"word\")) im_text = im_text |> subset_im() |> core() #> [1] \"adding graph summaries (coreness and connected components).\" bff(pcs, im_text, num_best = 4) #> # A tibble: 10 × 5 #>    factor     word1               word2                word3               word4 #>    <chr>      <chr>               <chr>                <chr>               <chr> #>  1 pc_01_rows data/Description    ggplot2/Description  ggplot2/Title       mode… #>  2 pc_02_rows shiny/Description   tidy/Description     shiny/Title         tidy… #>  3 pc_03_rows shiny/Description   shiny/Title          analysis/Descripti… apps… #>  4 pc_04_rows tidy/Description    tidy/Title           data/Description    ggpl… #>  5 pc_05_rows spatial/Description models/Description   geometrical/Descri… fitt… #>  6 pc_06_rows fitted/Description  spatial/Description  models/Description  netw… #>  7 pc_07_rows shiny/Description   mlr3/Description     shiny/Title         fore… #>  8 pc_08_rows spatial/Description patterns/Description data/Description    form… #>  9 pc_09_rows spatial/Description raster/Description   goal/Description    ggpl… #> 10 pc_10_rows models/Description  mixed/Description    methods/Description para…"},{"path":"/reference/clean.html","id":null,"dir":"Reference","previous_headings":"","what":"clean\nGiven and interaction_model, this returns a new interaction_model that is the ","title":"clean\nGiven and interaction_model, this returns a new interaction_model that is the ","text":"clean Given interaction_model, returns new interaction_model \"k-core\" \"largest connected component\" original interaction_model.  function recommended diagnose(im) shows majority rows/columns 1, 2, 3 connections.  case, data potentially sparse pca.  simply throwing away rows/columns weakly connected, reduce connections remain.  k-core get keep iterating.  particular, find largest subset rows columns interaction_model every row column least core_threshold number connections \"data points\" interaction_tibble.  exactly k-core row columns correspond unique elements (non-overlapping).  elements rows match elements columns, elements represented twice... row column.  possible one retained.","code":""},{"path":"/reference/clean.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"clean\nGiven and interaction_model, this returns a new interaction_model that is the ","text":"","code":"clean(im, core_threshold = 3)"},{"path":"/reference/clean.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"clean\nGiven and interaction_model, this returns a new interaction_model that is the ","text":"im interaction_model cleaned. core_threshold integer value sets minimum number connections row column must included final interaction model. Defaults 3.","code":""},{"path":"/reference/clean.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"clean\nGiven and interaction_model, this returns a new interaction_model that is the ","text":"Returns modified version input interaction model (type im), represents k-core largest connected component based specified core_threshold. cleaned interaction model include rows columns meet minimum number connections defined core_threshold.","code":""},{"path":"/reference/core.html","id":null,"dir":"Reference","previous_headings":"","what":"core\nGiven and interaction_model, this returns a new interaction_model that is the ","title":"core\nGiven and interaction_model, this returns a new interaction_model that is the ","text":"core Given interaction_model, returns new interaction_model \"k-core\" \"largest connected component\" original interaction_model.  function recommended diagnose(im) shows majority rows/columns 1, 2, 3 connections.  case, data potentially sparse pca.  simply throwing away rows/columns weakly connected, reduce connections remain.  k-core get keep iterating.  particular, find largest subset rows columns interaction_model every row column least core_threshold number connections \"data points\" interaction_tibble.  exactly k-core row columns correspond unique elements (non-overlapping).  elements rows match elements columns, elements represented twice... row column.  possible one retained.","code":""},{"path":"/reference/core.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"core\nGiven and interaction_model, this returns a new interaction_model that is the ","text":"","code":"core(im_input, core_threshold = 3)"},{"path":"/reference/core.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"core\nGiven and interaction_model, this returns a new interaction_model that is the ","text":"core_threshold integer value sets minimum number connections row column must included final interaction model. Defaults 3. im interaction_model cleaned.","code":""},{"path":"/reference/core.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"core\nGiven and interaction_model, this returns a new interaction_model that is the ","text":"Returns modified version input interaction model (type im), represents k-core largest connected component based specified core_threshold. cleaned interaction model include rows columns meet minimum number connections defined core_threshold.","code":""},{"path":"/reference/diagnose.html","id":null,"dir":"Reference","previous_headings":"","what":"diagnose_formula — diagnose","title":"diagnose_formula — diagnose","text":"function helps see \"enough data\" pca return reliable results. particular, examine degree distribution printout plot. Perhaps run function running pca.","code":""},{"path":"/reference/diagnose.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"diagnose_formula — diagnose","text":"","code":"diagnose(im, make_plot = TRUE, nbins = 30)"},{"path":"/reference/diagnose.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"diagnose_formula — diagnose","text":"make_plot","code":""},{"path":"/reference/diagnose.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"diagnose_formula — diagnose","text":"","code":"library(nycflights13) im = make_interaction_model(flights, ~(month&day)*dest) diagnose(im) #> Warning: log-10 transformation introduced infinite values. #> Warning: Removed 28 rows containing missing values or values outside the scale range #> (`geom_bar()`).  #> # A tibble: 6 × 3 #>   measurement      dest `month & day` #>   <chr>           <dbl>         <dbl> #> 1 number_of_items   105           365 #> 2 average_degree    297            86 #> 3 median_degree     365            86 #> 4 percent_le_1        2             0 #> 5 percent_le_2        2             0 #> 6 percent_le_3        2             0"},{"path":"/reference/dot-make_interaction_model_completion.html","id":null,"dir":"Reference","previous_headings":"","what":"Custom completion function for make_interaction_model — .make_interaction_model_completion","title":"Custom completion function for make_interaction_model — .make_interaction_model_completion","text":"Custom completion function make_interaction_model","code":""},{"path":"/reference/dot-make_interaction_model_completion.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Custom completion function for make_interaction_model — .make_interaction_model_completion","text":"","code":".make_interaction_model_completion(.data, formula)"},{"path":"/reference/dot-make_interaction_model_completion.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Custom completion function for make_interaction_model — .make_interaction_model_completion","text":".data tibble passed make_interaction_model formula formula passed make_interaction_model","code":""},{"path":"/reference/extract_interaction.html","id":null,"dir":"Reference","previous_headings":"","what":"extract_interaction (internal) — extract_interaction","title":"extract_interaction (internal) — extract_interaction","text":"extract_interaction (internal)","code":""},{"path":"/reference/extract_interaction.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"extract_interaction (internal) — extract_interaction","text":"","code":"extract_interaction(str)"},{"path":"/reference/extract_interaction.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"extract_interaction (internal) — extract_interaction","text":"str","code":""},{"path":"/reference/extract_interaction.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"extract_interaction (internal) — extract_interaction","text":"vector terms inside interaction","code":""},{"path":"/reference/extract_variables.html","id":null,"dir":"Reference","previous_headings":"","what":"extract_variables (internal) — extract_variables","title":"extract_variables (internal) — extract_variables","text":"extract_variables (internal)","code":""},{"path":"/reference/extract_variables.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"extract_variables (internal) — extract_variables","text":"","code":"extract_variables(str)"},{"path":"/reference/extract_variables.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"extract_variables (internal) — extract_variables","text":"str","code":""},{"path":"/reference/get_Matrix.html","id":null,"dir":"Reference","previous_headings":"","what":"get_Matrix — get_Matrix","title":"get_Matrix — get_Matrix","text":"get_Matrix","code":""},{"path":"/reference/get_Matrix.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"get_Matrix — get_Matrix","text":"","code":"get_Matrix(interaction_model, import_names = FALSE)"},{"path":"/reference/get_Matrix.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"get_Matrix — get_Matrix","text":"interaction_model","code":""},{"path":"/reference/glaplacian.html","id":null,"dir":"Reference","previous_headings":"","what":"glaplacian — glaplacian","title":"glaplacian — glaplacian","text":"Normalizes regularizes sparse adjacency Matrix deg_row deg_col number non-zero elements row/column","code":""},{"path":"/reference/glaplacian.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"glaplacian — glaplacian","text":"","code":"glaplacian(A, regularize = TRUE)"},{"path":"/reference/glaplacian.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"glaplacian — glaplacian","text":"regularize","code":""},{"path":"/reference/itty_pivot.html","id":null,"dir":"Reference","previous_headings":"","what":"itty_pivot (internal) — itty_pivot","title":"itty_pivot (internal) — itty_pivot","text":"used diagnose","code":""},{"path":"/reference/itty_pivot.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"itty_pivot (internal) — itty_pivot","text":"","code":"itty_pivot(itty_tibby)"},{"path":"/reference/itty_pivot.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"itty_pivot (internal) — itty_pivot","text":"itty_tibby","code":""},{"path":"/reference/localization.html","id":null,"dir":"Reference","previous_headings":"","what":"localization — localization","title":"localization — localization","text":"Plots degree vs leverage; specifically, residual log(leverage)~log(degree) log(degree).","code":""},{"path":"/reference/localization.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"localization — localization","text":"","code":"localization(pcs)"},{"path":"/reference/localization.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"localization — localization","text":"pcs","code":""},{"path":"/reference/make_deg_lev_resid.html","id":null,"dir":"Reference","previous_headings":"","what":"make_deg_lev_resid (Internal) — make_deg_lev_resid","title":"make_deg_lev_resid (Internal) — make_deg_lev_resid","text":"make_deg_lev_resid (Internal)","code":""},{"path":"/reference/make_deg_lev_resid.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"make_deg_lev_resid (Internal) — make_deg_lev_resid","text":"","code":"make_deg_lev_resid(lev_tib)"},{"path":"/reference/make_deg_lev_resid.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"make_deg_lev_resid (Internal) — make_deg_lev_resid","text":"lev_tib","code":""},{"path":"/reference/make_interaction_model.html","id":null,"dir":"Reference","previous_headings":"","what":"make_interaction_model — make_interaction_model","title":"make_interaction_model — make_interaction_model","text":"generates interaction_model object.  comfortable thinking matrices, can think matrix-like-object.","code":""},{"path":"/reference/make_interaction_model.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"make_interaction_model — make_interaction_model","text":"","code":"make_interaction_model(   .data,   formula,   duplicates = \"add\",   parse_text = FALSE,   dropNA = TRUE,   data_prefix = NULL,   ... )"},{"path":"/reference/make_interaction_model.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"make_interaction_model — make_interaction_model","text":".data tibble contains variables formula. exception left-hand-side can 1 need .data. formula formula, like outcome ~ row_id * (measurement_type & context). ... additional arguments passed tidytext::unnest_tokens","code":""},{"path":"/reference/make_interaction_model.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"make_interaction_model — make_interaction_model","text":"list four elements.  First, interaction_tibble, akin sparse matrix triplet form. Second, row_universe akin row names , tidy form.  Thir, column_universe like row_universe. Fourth, settings.","code":""},{"path":"/reference/make_interaction_model.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"make_interaction_model — make_interaction_model","text":"","code":"library(nycflights13) im = make_interaction_model(flights,~(month & day)*dest) names(im) #> [1] \"interaction_tibble\" \"row_universe\"       \"column_universe\"    #> [4] \"settings\"           im$row_universe #> # A tibble: 365 × 4 #>    month   day     n row_num #>    <int> <int> <int>   <int> #>  1    11    27  1014       1 #>  2     7    11  1006       2 #>  3     7     8  1004       3 #>  4     7    10  1004       4 #>  5    12     2  1004       5 #>  6     7    18  1003       6 #>  7     7    25  1003       7 #>  8     7    12  1002       8 #>  9     7     9  1001       9 #> 10     7    17  1001      10 #> # ℹ 355 more rows im$column_universe #> # A tibble: 105 × 3 #>    dest      n col_num #>    <chr> <int>   <int> #>  1 ORD   17283       1 #>  2 ATL   17215       2 #>  3 LAX   16174       3 #>  4 BOS   15508       4 #>  5 MCO   14082       5 #>  6 CLT   14064       6 #>  7 SFO   13331       7 #>  8 FLL   12055       8 #>  9 MIA   11728       9 #> 10 DCA    9705      10 #> # ℹ 95 more rows im$interaction_tibble #> # A tibble: 31,229 × 3 #>    row_num col_num outcome #>      <int>   <int>   <dbl> #>  1       1       1      52 #>  2       1       2      51 #>  3       1       3      49 #>  4       1       4      43 #>  5       1       5      40 #>  6       1       6      42 #>  7       1       7      43 #>  8       1       8      38 #>  9       1       9      37 #> 10       1      10      28 #> # ℹ 31,219 more rows im$settings #> $fo #> 1 ~ (month & day) * dest #> <environment: 0x7f9ba08a5ce0> #>  #> $data_prefix #> NULL #>  #> $outcome_aggregation #> [1] \"count\" #>  #> $outcome_variables #> [1] \"outcome_unweighted_1\" #>  #> $row_variables #> [1] \"month\" \"day\"   #>  #> $column_variables #> [1] \"dest\" #>  # you can extract the sparse Matrix: A = longpca:::get_Matrix(im,  import_names = TRUE) str(A) #> Formal class 'dgCMatrix' [package \"Matrix\"] with 6 slots #>   ..@ i       : int [1:31229] 0 1 2 3 4 5 6 7 8 9 ... #>   ..@ p       : int [1:106] 0 365 730 1095 1460 1825 2190 2555 2920 3285 ... #>   ..@ Dim     : int [1:2] 365 105 #>   ..@ Dimnames:List of 2 #>   .. ..$ : chr [1:365] \"27/11\" \"11/7\" \"8/7\" \"10/7\" ... #>   .. ..$ : chr [1:105] \"ORD\" \"ATL\" \"LAX\" \"BOS\" ... #>   ..@ x       : num [1:31229] 52 55 55 55 49 54 55 55 54 55 ... #>   ..@ factors : list() im = make_interaction_model(all_packages, ~Package*Imports, parse_text = TRUE) names(im) #> [1] \"interaction_tibble\" \"row_universe\"       \"column_universe\"    #> [4] \"settings\"           im$row_universe #> # A tibble: 20,319 × 3 #>    Package                n row_num #>    <chr>              <int>   <int> #>  1 Seurat                64       1 #>  2 tidyverse             60       2 #>  3 radiant.data          58       3 #>  4 radiant.model         58       4 #>  5 SSDM                  55       5 #>  6 BasketballAnalyzeR    53       6 #>  7 tRigon                49       7 #>  8 AFM                   48       8 #>  9 dextergui             48       9 #> 10 proteus               48      10 #> # ℹ 20,309 more rows im$column_universe #> # A tibble: 6,230 × 4 #>    from_text token        n col_num #>    <chr>     <chr>    <int>   <int> #>  1 Imports   stats     5442       1 #>  2 Imports   utils     3423       2 #>  3 Imports   dplyr     3299       3 #>  4 Imports   methods   3210       4 #>  5 Imports   ggplot2   3135       5 #>  6 Imports   rcpp      2548       6 #>  7 Imports   rlang     2172       7 #>  8 Imports   graphics  2158       8 #>  9 Imports   magrittr  1954       9 #> 10 Imports   stringr   1698      10 #> # ℹ 6,220 more rows im$interaction_tibble #> # A tibble: 114,833 × 3 #>    row_num col_num outcome #>      <int>   <int>   <dbl> #>  1       1       1       1 #>  2       1       2       1 #>  3       1       5       1 #>  4       1       6       1 #>  5       1       7       1 #>  6       1       8       1 #>  7       1      12       1 #>  8       1      13       1 #>  9       1      14       1 #> 10       1      15       1 #> # ℹ 114,823 more rows im$settings #> $fo #> 1 ~ Package * Imports #> <environment: 0x7f9bb01affa8> #>  #> $data_prefix #> [1] \"text\" #>  #> $outcome_aggregation #> [1] \"count\" #>  #> $outcome_variables #> [1] \"outcome_unweighted_1\" #>  #> $row_variables #> [1] \"Package\" #>  #> $column_variables #> [1] \"from_text\" \"token\"     #>  # with text, there is often a great number of weakly connected words (words that appear once). # you can remove these words that appear less than 10 times (and documents that have less than 10 words) via: core(im, core_threshold = 10) #> [1] \"adding graph summaries (coreness and connected components).\" #> $row_universe #> # A tibble: 3,058 × 5 #>    Package                n coreness component_label row_num #>    <chr>              <int>    <dbl>           <dbl>   <int> #>  1 Seurat                64       16               1       1 #>  2 tidyverse             60       16               1       2 #>  3 radiant.data          58       16               1       3 #>  4 radiant.model         58       16               1       4 #>  5 SSDM                  55       16               1       5 #>  6 BasketballAnalyzeR    53       16               1       6 #>  7 tRigon                49       16               1       7 #>  8 AFM                   48       16               1       8 #>  9 dextergui             48       16               1       9 #> 10 proteus               48       16               1      10 #> # ℹ 3,048 more rows #>  #> $column_universe #> # A tibble: 666 × 6 #>    from_text token        n coreness component_label col_num #>    <chr>     <chr>    <int>    <dbl>           <dbl>   <int> #>  1 Imports   stats     5442       16               1       1 #>  2 Imports   utils     3423       16               1       2 #>  3 Imports   dplyr     3299       16               1       3 #>  4 Imports   methods   3210       16               1       4 #>  5 Imports   ggplot2   3135       16               1       5 #>  6 Imports   rcpp      2548       16               1       6 #>  7 Imports   rlang     2172       16               1       7 #>  8 Imports   graphics  2158       16               1       8 #>  9 Imports   magrittr  1954       16               1       9 #> 10 Imports   stringr   1698       16               1      10 #> # ℹ 656 more rows #>  # core retains the k-core of the \"largest connected component\" in the bipartite graph between rows and columns.  library(dplyr) #>  #> Attaching package: ‘dplyr’ #> The following objects are masked from ‘package:stats’: #>  #>     filter, lag #> The following objects are masked from ‘package:base’: #>  #>     intersect, setdiff, setequal, union # You can provide more than two text columns to make_interaction_model: im_text = make_interaction_model(top_packages, ~Package*(Title & Description), parse_text= TRUE) im_text$column_universe |> arrange(desc(n)) #> # A tibble: 9,800 × 4 #>    from_text   token         n col_num #>    <chr>       <chr>     <int>   <int> #>  1 Description and        2571       1 #>  2 Description the        1999       2 #>  3 Description of         1388       3 #>  4 Description for        1350       4 #>  5 Description to         1104       5 #>  6 Description a          1013       6 #>  7 Description in          722       7 #>  8 Description functions   581       8 #>  9 Description data        541       9 #> 10 Description package     515      10 #> # ℹ 9,790 more rows # remove stop words by removing them from the column_universe, #  then use the function subset_im to renumber the columns/rows and remove any lines from interaction_tibble im_text$column_universe = im_text$column_universe |> anti_join(tidytext::stop_words, by = c(\"token\"=\"word\")) im_text = im_text |> subset_im() im_text$column_universe |> arrange(desc(n)) #> # A tibble: 9,214 × 4 #>    from_text   token         n col_num #>    <chr>       <chr>     <int>   <int> #>  1 Description functions   581       1 #>  2 Description data        541       2 #>  3 Description package     515       3 #>  4 Description models      319       4 #>  5 Description doi         285       5 #>  6 Description methods     226       6 #>  7 Description analysis    218       7 #>  8 Description function    164       8 #>  9 Description model       155       9 #> 10 Description based       142      10 #> # ℹ 9,204 more rows"},{"path":"/reference/make_interaction_model_from_variables.html","id":null,"dir":"Reference","previous_headings":"","what":"make_interaction_model_from_variables (internal to make_interaction_tibble and text2sparse) — make_interaction_model_from_variables","title":"make_interaction_model_from_variables (internal to make_interaction_tibble and text2sparse) — make_interaction_model_from_variables","text":"make_interaction_model_from_variables (internal make_interaction_tibble text2sparse)","code":""},{"path":"/reference/make_interaction_model_from_variables.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"make_interaction_model_from_variables (internal to make_interaction_tibble and text2sparse) — make_interaction_model_from_variables","text":"","code":"make_interaction_model_from_variables(   tib,   row_column,   column_column,   outcome_column,   vars = NULL,   dropNA,   duplicates )"},{"path":"/reference/make_interaction_model_from_variables.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"make_interaction_model_from_variables (internal to make_interaction_tibble and text2sparse) — make_interaction_model_from_variables","text":"outcome_column","code":""},{"path":"/reference/make_leverage.html","id":null,"dir":"Reference","previous_headings":"","what":"make_leverage (internal for localization) — make_leverage","title":"make_leverage (internal for localization) — make_leverage","text":"make_leverage (internal localization)","code":""},{"path":"/reference/make_leverage.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"make_leverage (internal for localization) — make_leverage","text":"","code":"make_leverage(pcs)"},{"path":"/reference/make_leverage.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"make_leverage (internal for localization) — make_leverage","text":"pcs","code":""},{"path":"/reference/make_sparse_output.html","id":null,"dir":"Reference","previous_headings":"","what":"make_sparse_output (internal to rotate) — make_sparse_output","title":"make_sparse_output (internal to rotate) — make_sparse_output","text":"make_sparse_output (internal rotate)","code":""},{"path":"/reference/make_sparse_output.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"make_sparse_output (internal to rotate) — make_sparse_output","text":"","code":"make_sparse_output(sparse_pc_mat, rot_mat, new_prefix)"},{"path":"/reference/make_sparse_output.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"make_sparse_output (internal to rotate) — make_sparse_output","text":"old_prefix","code":""},{"path":"/reference/old_make_interaction_model.html","id":null,"dir":"Reference","previous_headings":"","what":"old_make_interaction_model — old_make_interaction_model","title":"old_make_interaction_model — old_make_interaction_model","text":"generates interaction_model object.  comfortable thinking matrices, can think matrix-like-object.","code":""},{"path":"/reference/old_make_interaction_model.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"old_make_interaction_model — old_make_interaction_model","text":"","code":"old_make_interaction_model(   fo,   tib,   duplicates = \"add\",   parse_text = FALSE,   dropNA = TRUE,   data_prefix = NULL,   ... )"},{"path":"/reference/old_make_interaction_model.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"old_make_interaction_model — old_make_interaction_model","text":"fo formula, like outcome ~ (row_nums & context) * measurement_type. tib tibble contains variables formula. exception left-hand-side can 1 need tib. parse_text set TRUE, right side * (.e. measurement_type) parsed sequence tokens via tidytext::unnest_tokens.  Additional arguments ... passed unnest_tokens.  example, adding to_lower = FALSE ensure case kept. Additionally, set token something words (ngrams skip_ngrams additionally specify n = ).  See unnest_token arguments. dropNA recommended.  drops rows tib NA's among essential variables.","code":""},{"path":"/reference/old_make_interaction_model.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"old_make_interaction_model — old_make_interaction_model","text":"list four elements.  First, interaction_tibble, akin sparse matrix triplet form. Second, row_universe akin row names , tidy form.  Thir, column_universe like row_universe. Fourth, settings.","code":""},{"path":"/reference/old_make_interaction_model.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"old_make_interaction_model — old_make_interaction_model","text":"","code":"library(nycflights13) im = old_make_interaction_model(~(month & day)*dest, flights) names(im) #> [1] \"interaction_tibble\" \"row_universe\"       \"column_universe\"    #> [4] \"settings\"           im$row_universe #> # A tibble: 365 × 4 #>    month   day     n row_num #>    <int> <int> <int>   <int> #>  1    11    27  1014       1 #>  2     7    11  1006       2 #>  3     7     8  1004       3 #>  4     7    10  1004       4 #>  5    12     2  1004       5 #>  6     7    18  1003       6 #>  7     7    25  1003       7 #>  8     7    12  1002       8 #>  9     7     9  1001       9 #> 10     7    17  1001      10 #> # ℹ 355 more rows im$column_universe #> # A tibble: 105 × 3 #>    dest      n col_num #>    <chr> <int>   <int> #>  1 ORD   17283       1 #>  2 ATL   17215       2 #>  3 LAX   16174       3 #>  4 BOS   15508       4 #>  5 MCO   14082       5 #>  6 CLT   14064       6 #>  7 SFO   13331       7 #>  8 FLL   12055       8 #>  9 MIA   11728       9 #> 10 DCA    9705      10 #> # ℹ 95 more rows im$interaction_tibble #> # A tibble: 31,229 × 3 #>    row_num col_num outcome #>      <int>   <int>   <dbl> #>  1       1       1      52 #>  2       1       2      51 #>  3       1       3      49 #>  4       1       4      43 #>  5       1       5      40 #>  6       1       6      42 #>  7       1       7      43 #>  8       1       8      38 #>  9       1       9      37 #> 10       1      10      28 #> # ℹ 31,219 more rows im$settings #> $fo #> 1 ~ (month & day) * dest #> <environment: 0x7f9b95a23ed8> #>  #> $data_prefix #> NULL #>  #> $outcome_aggregation #> [1] \"count\" #>  #> $outcome_variables #> [1] \"outcome_unweighted_1\" #>  #> $row_variables #> [1] \"month\" \"day\"   #>  #> $column_variables #> [1] \"dest\" #>  # you can extract the sparse Matrix: A = longpca:::get_Matrix(im,  import_names = TRUE) str(A) #> Formal class 'dgCMatrix' [package \"Matrix\"] with 6 slots #>   ..@ i       : int [1:31229] 0 1 2 3 4 5 6 7 8 9 ... #>   ..@ p       : int [1:106] 0 365 730 1095 1460 1825 2190 2555 2920 3285 ... #>   ..@ Dim     : int [1:2] 365 105 #>   ..@ Dimnames:List of 2 #>   .. ..$ : chr [1:365] \"27/11\" \"11/7\" \"8/7\" \"10/7\" ... #>   .. ..$ : chr [1:105] \"ORD\" \"ATL\" \"LAX\" \"BOS\" ... #>   ..@ x       : num [1:31229] 52 55 55 55 49 54 55 55 54 55 ... #>   ..@ factors : list() im = old_make_interaction_model(~Package*Imports, all_packages, parse_text = TRUE) names(im) #> [1] \"interaction_tibble\" \"row_universe\"       \"column_universe\"    #> [4] \"settings\"           im$row_universe #> # A tibble: 20,319 × 3 #>    Package                n row_num #>    <chr>              <int>   <int> #>  1 Seurat                64       1 #>  2 tidyverse             60       2 #>  3 radiant.data          58       3 #>  4 radiant.model         58       4 #>  5 SSDM                  55       5 #>  6 BasketballAnalyzeR    53       6 #>  7 tRigon                49       7 #>  8 AFM                   48       8 #>  9 dextergui             48       9 #> 10 proteus               48      10 #> # ℹ 20,309 more rows im$column_universe #> # A tibble: 6,230 × 4 #>    from_text token        n col_num #>    <chr>     <chr>    <int>   <int> #>  1 Imports   stats     5442       1 #>  2 Imports   utils     3423       2 #>  3 Imports   dplyr     3299       3 #>  4 Imports   methods   3210       4 #>  5 Imports   ggplot2   3135       5 #>  6 Imports   rcpp      2548       6 #>  7 Imports   rlang     2172       7 #>  8 Imports   graphics  2158       8 #>  9 Imports   magrittr  1954       9 #> 10 Imports   stringr   1698      10 #> # ℹ 6,220 more rows im$interaction_tibble #> # A tibble: 114,833 × 3 #>    row_num col_num outcome #>      <int>   <int>   <dbl> #>  1       1       1       1 #>  2       1       2       1 #>  3       1       5       1 #>  4       1       6       1 #>  5       1       7       1 #>  6       1       8       1 #>  7       1      12       1 #>  8       1      13       1 #>  9       1      14       1 #> 10       1      15       1 #> # ℹ 114,823 more rows im$settings #> $fo #> 1 ~ Package * Imports #> <environment: 0x7f9b95704038> #>  #> $data_prefix #> [1] \"text\" #>  #> $outcome_aggregation #> [1] \"count\" #>  #> $outcome_variables #> [1] \"outcome_unweighted_1\" #>  #> $row_variables #> [1] \"Package\" #>  #> $column_variables #> [1] \"from_text\" \"token\"     #>"},{"path":"/reference/pair.html","id":null,"dir":"Reference","previous_headings":"","what":"Internal — pair","title":"Internal — pair","text":"Internal","code":""},{"path":"/reference/pair.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Internal — pair","text":"","code":"pair(u, n = 1000)"},{"path":"/reference/pair.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Internal — pair","text":"n","code":""},{"path":"/reference/parse_formula.html","id":null,"dir":"Reference","previous_headings":"","what":"parse_variables (internal) — parse_formula","title":"parse_variables (internal) — parse_formula","text":"parse_variables (internal)","code":""},{"path":"/reference/parse_formula.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"parse_variables (internal) — parse_formula","text":"","code":"parse_formula(fo, tib)"},{"path":"/reference/parse_formula.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"parse_variables (internal) — parse_formula","text":"tib","code":""},{"path":"/reference/pca.html","id":null,"dir":"Reference","previous_headings":"","what":"pca — pca","title":"pca — pca","text":"pca","code":""},{"path":"/reference/pca.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"pca — pca","text":"","code":"pca(im, k, method_prefix = \"pc\", regularize = TRUE, sqrt_counts = TRUE)"},{"path":"/reference/pca.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"pca — pca","text":"method_prefix","code":""},{"path":"/reference/pca_average.html","id":null,"dir":"Reference","previous_headings":"","what":"pca_average — pca_average","title":"pca_average — pca_average","text":"performs pca matrix missing entries.","code":""},{"path":"/reference/pca_average.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"pca_average — pca_average","text":"","code":"pca_average(fo, tib, k)"},{"path":"/reference/pca_average.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"pca_average — pca_average","text":"k","code":""},{"path":"/reference/pca_count.html","id":null,"dir":"Reference","previous_headings":"","what":"pca_count — pca_count","title":"pca_count — pca_count","text":"first user function generate pcs.","code":""},{"path":"/reference/pca_count.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"pca_count — pca_count","text":"","code":"pca_count(fo, tib, k)"},{"path":"/reference/pca_count.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"pca_count — pca_count","text":"fo formula, like  ~ (row_ids & context) * measurement_type. left hand side left empty.  , converted 1. Either way, elements sparse matrix just counts. tib tibble contains variables formula. exception left-hand-side can 1 need tib. k number dimensions pca","code":""},{"path":"/reference/pca_count.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"pca_count — pca_count","text":"output list : (1) row_features whichever term first right hand side formula, (2) column_features whichever term second right hand side formula, (3) middle_B tibble corresponding diagonal matrix sparse triplet form, (4) settings list details.","code":""},{"path":"/reference/pca_na.html","id":null,"dir":"Reference","previous_headings":"","what":"pca_na — pca_na","title":"pca_na — pca_na","text":"performs pca interaction_model, (row_id,col_id) present data, presumed NA imputed.  contrasts pca function imputes missing values zero.","code":""},{"path":"/reference/pca_na.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"pca_na — pca_na","text":"","code":"pca_na(im, k)"},{"path":"/reference/pca_na.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"pca_na — pca_na","text":"k","code":""},{"path":"/reference/pca_sum.html","id":null,"dir":"Reference","previous_headings":"","what":"pca_sum — pca_sum","title":"pca_sum — pca_sum","text":"performs pca sparse Matrix specified formula tibble.","code":""},{"path":"/reference/pca_sum.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"pca_sum — pca_sum","text":"","code":"pca_sum(fo, tib, k)"},{"path":"/reference/pca_sum.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"pca_sum — pca_sum","text":"fo formula, like  outcome ~ (row_ids & context) * measurement_type. tib tibble contains variables formula. exception left-hand-side can 1 need tib. k number dimensions pca","code":""},{"path":"/reference/pca_sum.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"pca_sum — pca_sum","text":"output list : (1) row_features whichever term first right hand side formula, (2) column_features whichever term second right hand side formula, (3) middle_B tibble corresponding diagonal matrix sparse triplet form, (4) settings list details.","code":""},{"path":"/reference/pca_text.html","id":null,"dir":"Reference","previous_headings":"","what":"pca_text — pca_text","title":"pca_text — pca_text","text":"given formula ~ row_ids * text, text character string, construct matrix row's indexed row_ids columns (default) bag--words. Perform PCA matrix.","code":""},{"path":"/reference/pca_text.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"pca_text — pca_text","text":"","code":"pca_text(fo, tib, k, ...)"},{"path":"/reference/pca_text.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"pca_text — pca_text","text":"...","code":""},{"path":"/reference/pca_text.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"pca_text — pca_text","text":"Extended arguments ... passed tidytext::unnest_tokens. example ... token = \"ngrams\", n=2 construct matrix bigrams. TODO: make diagnose_text","code":""},{"path":"/reference/pick_dim.html","id":null,"dir":"Reference","previous_headings":"","what":"pick_dim — pick_dim","title":"pick_dim — pick_dim","text":"computes Z-scores cross-validated eigenvalues","code":""},{"path":"/reference/pick_dim.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"pick_dim — pick_dim","text":"","code":"pick_dim(im, dimMax = 20, num_bootstraps = 2)"},{"path":"/reference/pick_dim.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"pick_dim — pick_dim","text":"num_bootstraps","code":""},{"path":"/reference/pick_dim.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"pick_dim — pick_dim","text":"","code":"library(nycflights13) im = make_interaction_model(flights,~(month&day)*dest) cveig = pick_dim(im, dimMax = 7) plot(cveig)  cveig #> Estimated graph dimension:\t 5 #>  #> Number of bootstraps:\t\t 2 #> Edge splitting probabaility:\t 0.1 #> Significance level:\t\t 0.05 #>  #>  ------------ Summary of Tests ------------ #>  k          z        pvals         padj #>  1 165.640658 0.000000e+00 0.000000e+00 #>  2  12.498316 3.812471e-36 3.812471e-36 #>  3   8.146867 1.867363e-16 1.867363e-16 #>  4   3.603255 1.571284e-04 1.571284e-04 #>  5   2.478655 6.593945e-03 6.593945e-03 #>  6  -2.547305 9.945721e-01 9.945721e-01 #>  7  -5.260579 9.999999e-01 9.999999e-01 #>"},{"path":"/reference/plot.pc.html","id":null,"dir":"Reference","previous_headings":"","what":"plot.pc — plot.pc","title":"plot.pc — plot.pc","text":"creates five diagnostic plots: Screeplot: top k singular values L. Better screeplot: singular values 2:k (first one usually dominant difficult see elbow past ). \"localization plot\" similar (maybe exact?) stuff; row (column) compute degree leverage score.  Take log . Fit linear model log(leverage)~log(degree) plot residuals log(degree).  localization, suspect big curl right side. Pairs plot row_features. plot emphasized varimax paper. example plots , see clear radial streaks. pairs plot column_features.  pairs plots, 1000 points, code samples 1000 points probability proportional leverage scores.  plot k=10 dimensions.  k larger, plots first 5 last 5.","code":""},{"path":"/reference/plot.pc.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"plot.pc — plot.pc","text":"","code":"# S3 method for pc plot(pcs)"},{"path":"/reference/plot.pc.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"plot.pc — plot.pc","text":"pcs","code":""},{"path":"/reference/plot.pc.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"plot.pc — plot.pc","text":"","code":"library(nycflights13) pcs = pca_count(1 ~ (month & day)*(dest), flights, k = 6) plot(pcs)  #> Press [Enter] to continue to the next plot...  #> Press [Enter] to continue to the next plot... #> `geom_smooth()` using formula = 'y ~ s(x, bs = \"cs\")'  #> Press [Enter] to continue to the next plot...  #> Press [Enter] to continue to the next plot..."},{"path":"/reference/print.interaction_model.html","id":null,"dir":"Reference","previous_headings":"","what":"print interaction model — print.interaction_model","title":"print interaction model — print.interaction_model","text":"print interaction model","code":""},{"path":"/reference/print.interaction_model.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"print interaction model — print.interaction_model","text":"","code":"# S3 method for interaction_model print(im)"},{"path":"/reference/print.interaction_model.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"print interaction model — print.interaction_model","text":"im","code":""},{"path":"/reference/print.pc.html","id":null,"dir":"Reference","previous_headings":"","what":"print.pc — print.pc","title":"print.pc — print.pc","text":"print.pc","code":""},{"path":"/reference/print.pc.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"print.pc — print.pc","text":"","code":"# S3 method for pc print(pcs)"},{"path":"/reference/print.pc.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"print.pc — print.pc","text":"pcs","code":""},{"path":"/reference/remove_L_normalization.html","id":null,"dir":"Reference","previous_headings":"","what":"remove_L_normalization (internal to pca_mean/pca_average) — remove_L_normalization","title":"remove_L_normalization (internal to pca_mean/pca_average) — remove_L_normalization","text":"remove_L_normalization (internal pca_mean/pca_average)","code":""},{"path":"/reference/remove_L_normalization.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"remove_L_normalization (internal to pca_mean/pca_average) — remove_L_normalization","text":"","code":"remove_L_normalization(s_svd, A, orthogonalize = FALSE)"},{"path":"/reference/remove_L_normalization.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"remove_L_normalization (internal to pca_mean/pca_average) — remove_L_normalization","text":"orthogonalize","code":""},{"path":"/reference/rotate.html","id":null,"dir":"Reference","previous_headings":"","what":"rotate — rotate","title":"rotate — rotate","text":"perform varimax rotation rows columns.  mode specified, mode rotated.","code":""},{"path":"/reference/rotate.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"rotate — rotate","text":"","code":"rotate(pcs, mode = NULL)"},{"path":"/reference/rotate.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"rotate — rotate","text":"mode specify row column want rotate one mode.","code":""},{"path":"/reference/rotate.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"rotate — rotate","text":"","code":"im = make_interaction_model(all_packages, ~Package*Imports, parse_text = TRUE) pcs = pca(im, k = 10) # streaks(pcs) sparse_pcs = rotate(pcs) # notice how the rotation aligns the streaks with the axes... # streaks(sparse_pcs, \"columns\") # if you do not specify a mode, then the middle B matrix will not be strictly diagonal... image(longpca:::get_middle_matrix(sparse_pcs))  # if you rotate only the columns, then the middle B matrix is set to diagonal and this matrix is \"pushed into\" the other mode. sparse_columns_pcs = rotate(pcs, mode = \"columns\") # because we only rotated one mode, the B matrix is the identity matrix: image(longpca:::get_middle_matrix(sparse_columns_pcs))  # these values were pushed into the row_features.  You can see that their scale is drastically reduced: sparse_pcs$row_features$vpc_01_rows |> sd() #> [1] 0.9769102 sparse_columns_pcs$row_features$vpc_01_rows |> sd() #> [1] 5.553314e-05 # importantly, this is not simply the row pcs scaled by the singular values... it is also rotated by the varimax rotation for the columns... # here is the algebra using the SVD: # U D V' = (UDR)(VR)' # after rotating only the columns... # (UDR) gives the new row_features # (VR) gives the new column_features"},{"path":"/reference/select_universe.html","id":null,"dir":"Reference","previous_headings":"","what":"select_universe — select_universe","title":"select_universe — select_universe","text":"select_universe","code":""},{"path":"/reference/select_universe.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"select_universe — select_universe","text":"","code":"select_universe(pcs, mode = c(\"rows\", \"columns\"), any_dims = NA)"},{"path":"/reference/select_universe.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"select_universe — select_universe","text":"any_dims","code":""},{"path":"/reference/streaks.html","id":null,"dir":"Reference","previous_headings":"","what":"streaks — streaks","title":"streaks — streaks","text":"pairs plot.  Set type_mode either \"rows\" \"cols\".  plot_columns pick columns.","code":""},{"path":"/reference/streaks.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"streaks — streaks","text":"","code":"streaks(pcs, mode = \"rows\", plot_columns = NULL)"},{"path":"/reference/streaks.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"streaks — streaks","text":"plot_columns","code":""},{"path":[]},{"path":"/reference/summary.interaction_model.html","id":null,"dir":"Reference","previous_headings":"","what":"summary interaction model — summary.interaction_model","title":"summary interaction model — summary.interaction_model","text":"summary interaction model","code":""},{"path":"/reference/summary.interaction_model.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"summary interaction model — summary.interaction_model","text":"","code":"# S3 method for interaction_model summary(im)"},{"path":"/reference/summary.interaction_model.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"summary interaction model — summary.interaction_model","text":"im","code":""},{"path":"/reference/top.html","id":null,"dir":"Reference","previous_headings":"","what":"Title — top","title":"Title — top","text":"Title","code":""},{"path":"/reference/top.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Title — top","text":"","code":"top(pcs, this_dim, keep_how_many = 9, abs_cut_off = 3)"},{"path":"/reference/top.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Title — top","text":"dim","code":""},{"path":"/reference/top_features.html","id":null,"dir":"Reference","previous_headings":"","what":"top_features — top_features","title":"top_features — top_features","text":"top_features","code":""},{"path":"/reference/top_features.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"top_features — top_features","text":"","code":"top_features(tidy_features, pc_name_for_mode, keep_how_many)"},{"path":"/reference/top_features.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"top_features — top_features","text":"dim_string","code":""},{"path":"/reference/transpose_tibble.html","id":null,"dir":"Reference","previous_headings":"","what":"#' list_2_tib (internal)\n#'\n#' used for diagnose\n#'\n#' @param list_of_data\n#'\n#' @return\n#'\n#' @examples\nlist_2_tib = function(list_of_data)\ndplyr::bind_rows(lapply(list_of_data, itty_pivot)) — transpose_tibble","title":"#' list_2_tib (internal)\n#'\n#' used for diagnose\n#'\n#' @param list_of_data\n#'\n#' @return\n#'\n#' @examples\nlist_2_tib = function(list_of_data)\ndplyr::bind_rows(lapply(list_of_data, itty_pivot)) — transpose_tibble","text":"#' list_2_tib (internal) #' #' used diagnose #' #' @param list_of_data #' #' @return #' #' @examples list_2_tib = function(list_of_data) dplyr::bind_rows(lapply(list_of_data, itty_pivot))","code":""},{"path":"/reference/transpose_tibble.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"#' list_2_tib (internal)\n#'\n#' used for diagnose\n#'\n#' @param list_of_data\n#'\n#' @return\n#'\n#' @examples\nlist_2_tib = function(list_of_data)\ndplyr::bind_rows(lapply(list_of_data, itty_pivot)) — transpose_tibble","text":"","code":"transpose_tibble(data)"},{"path":"/reference/transpose_tibble.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"#' list_2_tib (internal)\n#'\n#' used for diagnose\n#'\n#' @param list_of_data\n#'\n#' @return\n#'\n#' @examples\nlist_2_tib = function(list_of_data)\ndplyr::bind_rows(lapply(list_of_data, itty_pivot)) — transpose_tibble","text":"data","code":""},{"path":"/reference/transpose_tibble.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"#' list_2_tib (internal)\n#'\n#' used for diagnose\n#'\n#' @param list_of_data\n#'\n#' @return\n#'\n#' @examples\nlist_2_tib = function(list_of_data)\ndplyr::bind_rows(lapply(list_of_data, itty_pivot)) — transpose_tibble","text":"transpose_tibble (internal) used diagnose","code":""},{"path":[]},{"path":[]},{"path":[]},{"path":"/reference/update_lhs_to_1.html","id":null,"dir":"Reference","previous_headings":"","what":"update_lhs_to_1 (internal to pca_count) — update_lhs_to_1","title":"update_lhs_to_1 (internal to pca_count) — update_lhs_to_1","text":"update_lhs_to_1 (internal pca_count)","code":""},{"path":"/reference/update_lhs_to_1.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"update_lhs_to_1 (internal to pca_count) — update_lhs_to_1","text":"","code":"update_lhs_to_1(formula, quiet = FALSE)"},{"path":"/reference/update_lhs_to_1.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"update_lhs_to_1 (internal to pca_count) — update_lhs_to_1","text":"formula","code":""},{"path":"/reference/varimax_with_pre_rotation.html","id":null,"dir":"Reference","previous_headings":"","what":"varimax_with_pre_rotation (internal to rotate) — varimax_with_pre_rotation","title":"varimax_with_pre_rotation (internal to rotate) — varimax_with_pre_rotation","text":"varimax_with_pre_rotation (internal rotate)","code":""},{"path":"/reference/varimax_with_pre_rotation.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"varimax_with_pre_rotation (internal to rotate) — varimax_with_pre_rotation","text":"","code":"varimax_with_pre_rotation(matrix_to_rotate, pre_rotation)"},{"path":"/reference/varimax_with_pre_rotation.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"varimax_with_pre_rotation (internal to rotate) — varimax_with_pre_rotation","text":"pre_rotation","code":""}]
